{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c397832",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [22]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db630923-3b2a-4f00-a357-5c9fe1e3f534",
   "metadata": {
    "papermill": {
     "duration": 0.014736,
     "end_time": "2025-04-23T09:11:23.268880",
     "exception": false,
     "start_time": "2025-04-23T09:11:23.254144",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Superoscillation FMQA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f6a506-2403-4658-aaa0-97444fb58ad7",
   "metadata": {
    "papermill": {
     "duration": 0.012562,
     "end_time": "2025-04-23T09:11:23.294905",
     "exception": false,
     "start_time": "2025-04-23T09:11:23.282343",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 名詞定義\n",
    "<pre>\n",
    "- config, configs\n",
    "  - config  : 一個zone plate的組態\n",
    "  - configs : 多個zone plates的組態\n",
    "- fom, foms\n",
    "  - fom  : 一個zone plate的組態對應的fom\n",
    "  - foms : 多個zone plates的組態對應的fom \n",
    "- ring, rings\n",
    "  - ring  : 一個環的狀態（0或1）\n",
    "  - rings : 一個zone plate的環數\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3798591-e950-404b-b3b5-fc7942810a9a",
   "metadata": {
    "papermill": {
     "duration": 0.011451,
     "end_time": "2025-04-23T09:11:23.320065",
     "exception": false,
     "start_time": "2025-04-23T09:11:23.308614",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Note\n",
    "<pre>\n",
    "- SA不會將相同的結果自動合併(aggregate)，QA會 -> this is not a problem when sampling many times\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d521a6-21b0-4106-b4da-22eaece9afbc",
   "metadata": {
    "papermill": {
     "duration": 0.009738,
     "end_time": "2025-04-23T09:11:23.339975",
     "exception": false,
     "start_time": "2025-04-23T09:11:23.330237",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 進度（更新時間：2025/4/10 4:30am）\n",
    "<pre>\n",
    "(required)\n",
    "- read_file, add_new_data還沒完成\n",
    "- simulation部分的不允許重複數據還需要修正\n",
    "- 固定刪除前幾%的數據要寫成函數，然後這樣做的話最後的FOM圖就要刪除紅線（因為已經無法區分哪些是初始數據了）\n",
    "(optional)\n",
    "- save_file的部分還要再存intensity的數據\n",
    "- exact solver的add_new_data目前還是另外設定的\n",
    "- 把data統一存在一個PostgreSQL資料庫 -> 支持array(but not numpy)\n",
    "- 除了計算FOMs的函式之外，不應該有關於物理問題的部分（其他會使用到foms_calc的參數應該要用*args, *kwargs來傳） -> 通用性\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f8bce70-694a-474c-8589-2baaffe98a03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T09:11:23.360952Z",
     "iopub.status.busy": "2025-04-23T09:11:23.360727Z",
     "iopub.status.idle": "2025-04-23T09:11:25.733057Z",
     "shell.execute_reply": "2025-04-23T09:11:25.731924Z"
    },
    "papermill": {
     "duration": 2.38606,
     "end_time": "2025-04-23T09:11:25.735872",
     "exception": false,
     "start_time": "2025-04-23T09:11:23.349812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "import math\n",
    "import shutil\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.lines import Line2D\n",
    "from zone_plate import ZonePlate\n",
    "import S4\n",
    "from scipy import integrate\n",
    "\n",
    "\n",
    "# Setting Environment Variable (Has to be set before importing mxnet, or it will use multiprocessing automatically)\n",
    "os.environ['MXNET_CPU_WORKER_NTHREADS'] = '1'\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "\n",
    "# Factorization Machine\n",
    "import mxnet as mx\n",
    "from mxnet import nd\n",
    "from factorization_machine import FactorizationMachine as OriginalFactorizationMachine\n",
    "mx.random.seed(int(time.time()))\n",
    "\n",
    "# QUBO Sampler\n",
    "import dimod\n",
    "from dwave.system import DWaveSampler, EmbeddingComposite, FixedEmbeddingComposite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "980079b7-64e4-49c9-8bf6-083725ab5f87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T09:11:25.769314Z",
     "iopub.status.busy": "2025-04-23T09:11:25.768863Z",
     "iopub.status.idle": "2025-04-23T09:11:25.783602Z",
     "shell.execute_reply": "2025-04-23T09:11:25.782449Z"
    },
    "papermill": {
     "duration": 0.033834,
     "end_time": "2025-04-23T09:11:25.785643",
     "exception": false,
     "start_time": "2025-04-23T09:11:25.751809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FactorizationMachine(OriginalFactorizationMachine):\n",
    "\n",
    "    def __call__(self, xs):\n",
    "        \"\"\"Override __call__ to handle numpy array input automatically.\"\"\"\n",
    "        if isinstance(xs, np.ndarray):\n",
    "            xs = nd.array(xs)  # 自動轉換 numpy 陣列\n",
    "        return super().__call__(xs)\n",
    "    \n",
    "    def loss(self, dataset):\n",
    "        \"\"\"\n",
    "        用途：計算loss\n",
    "        計算公式：mean((ys - outputs)**2)\n",
    "    \n",
    "        參數\n",
    "        - dataset: [xs, ys]\n",
    "        \"\"\"\n",
    "        xs = nd.array(dataset[0])\n",
    "        ys = nd.array(dataset[1])\n",
    "        return nd.mean( ( ys - self(xs) ) ** 2 ).asscalar()\n",
    "\n",
    "    def _get_bhQ_scaled(self, scaling=True):\n",
    "        \"\"\"\n",
    "        原始程式有做scaling\n",
    "        \"\"\"\n",
    "        b, h, Q = self.get_bhQ()  # b: bias, h: linear, Q: quadratic (上三角部分)，皆為 numpy array\n",
    "        # print(h)\n",
    "        \n",
    "        h_max = np.max(np.abs(h))\n",
    "        Q_max = np.max(np.abs(Q))\n",
    "        scaling_factor = max(h_max, Q_max)\n",
    "        # print(scaling_factor)\n",
    "        if scaling:\n",
    "            b /= scaling_factor\n",
    "            h /= scaling_factor\n",
    "            Q /= scaling_factor\n",
    "        # print(h)\n",
    "        # sys.exit(1)\n",
    "\n",
    "        return b, h, Q\n",
    "\n",
    "    def bqm(self):\n",
    "        \"\"\"\n",
    "        用途：從 model 得到 bqm\n",
    "        \"\"\"\n",
    "        #b, h, Q = self.get_bhQ()\n",
    "        b, h, Q = self._get_bhQ_scaled()    # b: bias, h: linear, Q: quadratic (上三角部分)，皆為 numpy array\n",
    "\n",
    "        offset = b.item()  # 將 numpy array 轉為 Python 數值\n",
    "        linear = {i: h[i] for i in range(Q.shape[0])}\n",
    "        quadratic = {(i, j): Q[i, j] for i in range(Q.shape[0]) for j in range(i + 1, Q.shape[1])}\n",
    "\n",
    "        # BQM(linear, quadratic, offset, vartype)\n",
    "        return dimod.BinaryQuadraticModel(linear, quadratic, offset, dimod.BINARY)\n",
    "\n",
    "    def plot_Q_matrix(self, show_fig=False, path_fig=\"Q_matrix_heatmap.png\", save_fig=True, path_data=\"Q_matrix.npy\", save_data=True):\n",
    "        \"\"\"\n",
    "        用途：畫Q matrix的heatmap\n",
    "        \"\"\"\n",
    "        #b, h, Q = self.get_bhQ()\n",
    "        b, h, Q = self._get_bhQ_scaled()    # bias, linear, qudratic(upper tri)\n",
    "        Q = Q + Q.T\n",
    "        np.fill_diagonal(Q, h)\n",
    "        \n",
    "        if save_data:\n",
    "            np.save(path_data, Q)\n",
    "\n",
    "        if show_fig or save_fig:\n",
    "            plt.figure()\n",
    "            plt.imshow(Q, cmap=\"bwr\")\n",
    "            plt.colorbar()  # 顯示顏色對應的數值\n",
    "            plt.title(\"Q Matrix Heatmap\")\n",
    "\n",
    "            if save_fig:\n",
    "                plt.savefig(path_fig, bbox_inches='tight')\n",
    "            if show_fig:\n",
    "                plt.show()\n",
    "            else:\n",
    "                plt.close()\n",
    "\n",
    "    def save_model(self, path=\"model.params\"):\n",
    "        \"\"\"\n",
    "        用途：儲存model參數、optimizer狀態\n",
    "        \"\"\"\n",
    "        mx.nd.waitall()\n",
    "        # start_time = time.time()\n",
    "        self.save_parameters(path)\n",
    "        # end_time = time.time()\n",
    "        # print(f\"save parameters spend: {end_time - start_time} sec\")\n",
    "        \n",
    "        if self.trainer is not None:\n",
    "            # start_time = time.time()\n",
    "            self.trainer.save_states(path + \".trainer\")\n",
    "            # end_time = time.time()\n",
    "            # print(f\"save optimizer states spend: {end_time - start_time} sec\")\n",
    "\n",
    "    @staticmethod\n",
    "    def load_model(var_num, K, path=\"model.params\"):\n",
    "        \"\"\"\n",
    "        用途：讀取並返回model參數、optimizer狀態\n",
    "\n",
    "        參數\n",
    "        - var_num : qubits數\n",
    "        - K       : Factorization Machine的K\n",
    "        \"\"\"\n",
    "        model = FactorizationMachine(input_size=var_num, factorization_size=K, act=\"identity\")\n",
    "        model.load_parameters(path, ctx=mx.cpu())\n",
    "\n",
    "        # 需要先初始化 Trainer，然後才能載入 state\n",
    "        model.trainer = mx.gluon.Trainer(model.collect_params(), \"adam\")\n",
    "\n",
    "        try:\n",
    "            model.trainer.load_states(path + \".trainer\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"沒有讀到optimizer的參數\")\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "475c8885-1eaf-4f1b-a83b-785d2987fa32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T09:11:25.818381Z",
     "iopub.status.busy": "2025-04-23T09:11:25.818044Z",
     "iopub.status.idle": "2025-04-23T09:11:25.846453Z",
     "shell.execute_reply": "2025-04-23T09:11:25.845206Z"
    },
    "papermill": {
     "duration": 0.047907,
     "end_time": "2025-04-23T09:11:25.849153",
     "exception": false,
     "start_time": "2025-04-23T09:11:25.801246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_params_8 = {1: (5228, 5227, 1377, 1378, 5229, 5231, 5230, 2217),\n",
    "                    0: (5092, 5093, 5094, 1468, 5095, 5096, 1467, 5317, 1393, 1394, 1469),\n",
    "                    2: (1931, 1930, 1932, 1933, 4886, 4885, 1934, 1929),\n",
    "                    3: (2066, 2067, 5020, 5019, 2065, 5018, 2068, 2069, 5017, 1421),\n",
    "                    4: (1811, 1810, 4855, 1812, 1813, 4854, 1814),\n",
    "                    5: (5258, 5257, 5259, 5260, 5256, 1182, 1183, 1273, 1274, 5261, 2247),\n",
    "                    6: (5077, 1498, 1497, 1499, 5078, 5079, 5080, 5081),\n",
    "                    7: (2054, 5590, 5589, 2053, 2052, 2051, 5588, 5681, 2050, 5591),\n",
    "                    8: (5528, 5529, 5530, 5531, 5527, 1664, 2233, 5526),\n",
    "                    9: (5469, 5470, 5468, 5467, 5471, 1348, 1347, 5472, 1346, 5107),\n",
    "                    10: (1766, 1767, 4959, 4960, 4961, 1768, 4988, 1769, 1765),\n",
    "                    11: (1363, 5408, 5409, 5410, 5411, 5407, 1453),\n",
    "                    12: (5425, 5424, 5423, 5422, 1318, 5426, 1603, 5421, 1198),\n",
    "                    13: (5153, 5152, 5156, 1422, 1423, 1424, 5154, 5155),\n",
    "                    14: (1660, 4868, 1570, 1571, 1572, 1573, 1574, 1661, 4779, 4780, 4781, 4944),\n",
    "                    15: (1690, 1691, 1692, 1693, 4974, 4975, 4976, 4977, 2201, 1694),\n",
    "                    16: (1798, 1797, 5139, 5138, 1796, 1799, 5634, 5559, 5560, 5561),\n",
    "                    17: (5243, 5244, 5245, 5246, 1542, 1543, 1677, 5242, 1544),\n",
    "                    18: (5184, 1826, 1827, 4840, 1828, 4839, 1829, 1825),\n",
    "                    19: (5514, 5515, 5516, 5513, 5512, 5511, 5517),\n",
    "                    20: (4871, 4869, 1751, 1752, 1754, 1750, 1753, 4870),\n",
    "                    21: (4751, 1841, 4749, 1842, 1843, 4750, 1840, 1844),\n",
    "                    22: (2081, 2080, 2082, 2083, 2084, 4946, 2079, 4810, 4809, 1795),\n",
    "                    23: (5543, 1604, 5544, 5542, 5541, 5545, 5546),\n",
    "                    24: (4913, 1631, 1632, 1633, 4914, 4915, 1634, 4916),\n",
    "                    25: (5438, 5439, 1454, 5440, 5441, 5437, 5436, 5442, 2293, 2292, 5292),\n",
    "                    26: (5575, 5574, 5573, 5572, 5576, 2219, 2218, 5571),\n",
    "                    27: (5305, 2173, 5306, 5304, 2174, 2172, 5303),\n",
    "                    28: (2143, 2144, 5321, 5320, 5319, 2142, 2141, 5318),\n",
    "                    29: (5484, 5485, 5486, 5483, 5482, 1333, 1332, 5487),\n",
    "                    30: (5108, 1541, 5048, 5049, 5050, 1482, 1483, 1484, 5051),\n",
    "                    31: (1946, 1945, 1947, 1948, 1949, 4824, 4825, 1944),\n",
    "                    32: (4720, 1721, 2049, 4721, 4719, 1719, 1720, 1722, 1723, 1724),\n",
    "                    33: (1303, 5333, 5332, 5334, 5335, 5336, 1304, 1302, 1408, 5601),\n",
    "                    34: (1962, 1961, 1960, 1959, 1963, 1964, 5620, 5619),\n",
    "                    35: (5274, 5275, 5272, 5273, 1707, 1708, 5276),\n",
    "                    36: (1856, 4615, 1857, 4616, 1858, 1854, 1855, 1859),\n",
    "                    37: (4928, 4929, 1555, 1556, 1557, 1558, 1559, 4930, 4931),\n",
    "                    38: (1901, 1902, 1903, 1904, 5650, 5651, 1900, 1899, 1898, 4629, 4630),\n",
    "                    39: (5349, 5350, 1872, 1873, 5348, 5351, 1871, 5347),\n",
    "                    40: (1586, 1587, 5064, 5063, 5065, 5066, 1588, 1589, 4958),\n",
    "                    41: (5496, 5497, 5499, 5500, 5502, 5501, 5498),\n",
    "                    42: (2007, 2008, 2009, 2006, 4945, 2005),\n",
    "                    43: (1782, 1781, 1780, 1783, 5199, 5200, 1784, 1779),\n",
    "                    44: (1734, 1735, 1736, 1737, 4736, 1738, 4734, 4735, 1739),\n",
    "                    45: (1977, 1978, 1976, 1975, 1979, 1974),\n",
    "                    46: (1885, 1884, 4659, 4660, 1886, 1887, 1888, 1889, 2004),\n",
    "                    47: (5363, 5364, 5362, 1527, 1438, 5366, 5365, 1439),\n",
    "                    48: (1992, 1993, 1990, 1994, 1991, 4765),\n",
    "                    49: (5290, 5289, 5288, 5287, 5291, 1678, 1679),\n",
    "                    50: (2204, 5606, 5112, 5605, 5604, 5603, 2203, 2202, 5602),\n",
    "                    51: (2112, 2113, 2114, 2111, 2110, 2109, 5380),\n",
    "                    52: (1646, 1647, 1648, 1649, 4898, 4899, 5378, 4900, 4901),\n",
    "                    53: (5453, 5454, 5455, 5456, 2248, 5452),\n",
    "                    54: (5003, 1616, 1617, 1618, 5004, 5005, 1619, 1615, 5006),\n",
    "                    55: (2037, 2038, 2039, 2036, 5215, 5214, 2035, 5213, 5212, 2034),\n",
    "                    56: (2096, 2095, 2097, 2098, 2099, 2094, 5185, 2093, 5141),\n",
    "                    57: (2021, 2020, 2019, 2022, 2023, 2024, 4990, 4690),\n",
    "                    58: (5111, 2156, 2155, 5110, 5109, 2157, 2158, 2159),\n",
    "                    59: (5032, 1436, 1437, 1511, 1512, 1513, 5033, 5034, 5035, 1514, 1706),\n",
    "                    60: (2126, 2127, 2124, 2128, 2129, 5170, 2125, 5169),\n",
    "                    61: (2187, 5126, 2188, 2189, 2186, 5125, 5124, 2185, 5123),\n",
    "                    62: (5393, 5394, 5395, 5392, 5391, 5396, 1258, 1528, 1257, 5226, 5151),\n",
    "                    63: (1917, 1918, 1916, 1915, 1919, 5379, 1914, 5140)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4cec92e-daea-4b64-b625-e0cf15ba9af9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T09:11:25.884296Z",
     "iopub.status.busy": "2025-04-23T09:11:25.883627Z",
     "iopub.status.idle": "2025-04-23T09:11:27.942700Z",
     "shell.execute_reply": "2025-04-23T09:11:27.941175Z"
    },
    "papermill": {
     "duration": 2.080421,
     "end_time": "2025-04-23T09:11:27.946214",
     "exception": false,
     "start_time": "2025-04-23T09:11:25.865793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用的QPU: Advantage_system6.4\n",
      "QPU預設的Annealing Time: 20.0 µs\n",
      "設定QPU的Annealing Time: 20.0 µs\n",
      "*****顯示設定數據*****\n",
      "訓練集筆數：1000\n",
      "測試集比數：0\n",
      "*****　顯示結束　*****\n"
     ]
    }
   ],
   "source": [
    "# 定義Zone Plate的參數\n",
    "rings      = 60        # 定義一個zone plate的環數\n",
    "multiple   = 8.0       # 定義焦平面要算到幾倍波長（不能小於target_max_multiple）\n",
    "resolution = 2_000     # 定義要將\n",
    "\n",
    "# 定義計算FOM的參數\n",
    "####################################\n",
    "target_method       = \"intuitive3\"\n",
    "target_max_multiple = 8.0\n",
    "target_threshold    = 0.4\n",
    "beta                = 10\n",
    "#####################################\n",
    "# target_method              = \"step\"\n",
    "# target_max_multiple        = 8.0\n",
    "# target_step_point_multiple = 0.3\n",
    "##################################\n",
    "\n",
    "if (target_method == \"intuitive\") or (target_method == \"intuitive2\") or (target_method == \"intuitive3\"):\n",
    "    target = [target_method, target_max_multiple, target_threshold, beta, resolution]\n",
    "elif (target_method == \"step\"):\n",
    "    target = [target_method, target_max_multiple, target_step_point_multiple]\n",
    "else:\n",
    "    print(\"沒有這個target method\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# 定義初始數據的參數\n",
    "init_dataset_size          = 1000                                                 # read_file的參數n（包含訓練集、測試集）\n",
    "init_dataset_method        = \"read_n\"                                             # read_file的參數method\n",
    "init_dataset_top_k_percent = 1                                                    # read_file的參數k\n",
    "init_dataset_fom_thresh    = 0.4                                                  # read_file的參數thresh\n",
    "init_dataset_repeat        = True                                                 # read_file的參數repeat\n",
    "init_dataset_split_ratio   = 1                                                    # 多少比例要成為training set（testing筆數可以為0，但就不能用dynamic_FM）\n",
    "init_trainset_size         = int(init_dataset_size * init_dataset_split_ratio)    # 訓練集筆數\n",
    "init_testset_size          = init_dataset_size - init_trainset_size               # 測試集筆數\n",
    "if (init_trainset_size <= 0) or (init_testset_size < 0):\n",
    "    print(f\"訓練集or測試集筆數有問題（訓練集>0；測試集>=0）\")\n",
    "    print(f\"訓練集筆數: {init_trainset_size}\")\n",
    "    print(f\"測試集筆數: {init_testset_size}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# 定義FMQA整個迴圈的參數\n",
    "K                       = 8                              # Factorization Machine的參數K\n",
    "use_dynamic_FM          = False                          # 要不要用dynamic_FM\n",
    "dynamic_retrain         = False                          # dynamic_FM的參數\n",
    "ignore_original_dataset = False                          # （還沒新增）\n",
    "num_epoch               = 1_000                          # 不用dynamic_FM的話，FM要跑幾個epochs\n",
    "iteration               = 15                            # FMQA整個流程的iteration次數\n",
    "add_method              = \"min_fom\"                      # add_new_data的參數\n",
    "dynamic_sampling        = False                          # 要不要使用num_reads_adds_generator函數 -> 依照dataset筆數來決定要sample幾次、加多少新數據到原dataset（這個為True就設定num_adds_ratio, num_reads_ratio, num_adds_limit，然後num_adds, num_reads可以忽略）\n",
    "num_adds_ratio          = 0.1                            # num_reads_adds_generator的參數 -> 每個iteration要新增dataset筆數的幾倍的新數據\n",
    "num_reads_ratio         = 2                              # num_reads_adds_generator的參數 -> 每個iteration的sampling次數（這邊要寫新增數據筆數的幾倍）\n",
    "num_adds_limit          = 10                             # num_reads_adds_generator的參數 -> 設定num_adds的上限（不設定上限的話就設None）\n",
    "num_adds                = 200                           # 每個iteration要新增多少筆新數據（num_adds <= num_reads）\n",
    "num_reads               = 400                           # 每個iteration的sampling次數（這邊直接寫數字）\n",
    "new_data_split_ratio    = init_dataset_split_ratio\n",
    "if num_adds > num_reads:\n",
    "    print(\"num_adds > num_reads\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# 定義要使用的QUBO Sampler\n",
    "sampler_type = \"QA\"\n",
    "if sampler_type == \"Exact\":\n",
    "    if rings <= 16:\n",
    "        sampler = dimod.ExactSolver()\n",
    "    else:\n",
    "        print(\"環數太多，不能使用Exact Solver\")\n",
    "        sys.exit(1)\n",
    "elif sampler_type == \"SA\":\n",
    "    sampler = dimod.SimulatedAnnealingSampler()\n",
    "elif sampler_type == \"QA\":\n",
    "    annealing_time = 20.0    # 定義QA QUBO sampler的annealing time（單位：µs）\n",
    "    task_name = \"QA_Task_jiajun\"\n",
    "    qpu_advantage = DWaveSampler(solver={'chip_id': 'Advantage_system6.4'})\n",
    "    sampler = FixedEmbeddingComposite(qpu_advantage,embedding_params_8)\n",
    "    #sampler = EmbeddingComposite(DWaveSampler(solver = {\"name\": \"Advantage_system6.4\"}))\n",
    "    print(f\"使用的QPU: {sampler.child.properties.get('chip_id', 'NONE')}\")\n",
    "    print(f\"QPU預設的Annealing Time: {sampler.child.properties['default_annealing_time']} µs\")\n",
    "    print(f\"設定QPU的Annealing Time: {annealing_time} µs\")\n",
    "else:\n",
    "    print(\"沒有這個QUBO sampler\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# 顯示設定數據（尚未完成）\n",
    "print(\"*****顯示設定數據*****\")\n",
    "print(f\"訓練集筆數：{init_trainset_size}\")\n",
    "print(f\"測試集比數：{init_testset_size}\")\n",
    "print(\"*****　顯示結束　*****\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b176b2-75ca-4a16-8f92-0f5106a45cda",
   "metadata": {
    "papermill": {
     "duration": 0.025102,
     "end_time": "2025-04-23T09:11:28.000103",
     "exception": false,
     "start_time": "2025-04-23T09:11:27.975001",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 定義函式\n",
    "<pre>\n",
    "generate_unique_binary_array : (generate by DeepSeek, haven't been tested)\n",
    "foms_calc                    : Calculate the FOMs of the correspoding configs\n",
    "save_file                    : Save the configs and the corresponding intensities and FOMs to a specific path\n",
    "read_file                    : Read the configs and the corresponding FOMs from a specific path\n",
    "num_reads_adds_generator     : Define the quantity of num_reads and num_adds (for dynamic_sampling)\n",
    "add_new_data                 : Return the new data to be added to the training set and the testing set (use after sampling)\n",
    "sort_new_data                : Sort the new data (use after calling add_new_data)\n",
    "find_indices                 : (for the exact solver)\n",
    "plot_foms                    : 畫foms跟foms_modified的圖\n",
    "rm_best_model                : \n",
    "dynamic_FM                   : 返回testing loss最小的model（附：畫model的loss-epochs圖）\n",
    "plot_loss_iter               : 畫出每個iteration的training loss跟testing loss\n",
    "plot_energy_fom              : 畫出FMQA訓練過程中sample出的energy跟fom對i-th configuration的curve\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4fa1a9e-ea10-497c-b063-ac4187dae2a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T09:11:28.034266Z",
     "iopub.status.busy": "2025-04-23T09:11:28.033945Z",
     "iopub.status.idle": "2025-04-23T09:11:28.214638Z",
     "shell.execute_reply": "2025-04-23T09:11:28.213562Z"
    },
    "papermill": {
     "duration": 0.200037,
     "end_time": "2025-04-23T09:11:28.217408",
     "exception": false,
     "start_time": "2025-04-23T09:11:28.017371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_layer = 30\n",
    "print_spectrum = 0\n",
    "print_TR_percent = 0\n",
    "sio2_thick = 0.01\n",
    "ag_thick = 0.005\n",
    "hfo2_thick = 0.01\n",
    "al2o3_thick = 0.01\n",
    "al_thick = 0.005\n",
    "def n_al2o3(wl):\n",
    "    nsq = 1 + 1.4313493*wl**2/(wl**2-0.0726631**2) + 0.65054713*wl**2/(wl**2-0.1193242**2) + 5.3414021*wl**2/(wl**2-18.028251**2)\n",
    "    return (nsq)\n",
    "def n_sio2(wl):\n",
    "    nsq = 1 + 0.6961663*wl**2/(wl**2-0.0684043**2) + 0.4079426*wl**2/(wl**2-0.1162414**2) + 0.8974794*wl**2/(wl**2-9.896161**2)\n",
    "    return (nsq)\n",
    "def n_hfo2(wl):\n",
    "    return (np.square(1.875 + 6.28e-3/(wl**2) + 5.8e-4/(wl**4)))\n",
    "\n",
    "def s4_multilayer_FOM(x):\n",
    "    #新しいシミュレーションオブジェクトを設定\n",
    "    S=S4.New(Lattice=((1,0),(0,1)),NumBasis=1)\n",
    "    #S.SetOptions(PolarizationDecomposition = True)\n",
    "    pmma_string = 'PMMA'\n",
    "    sio2_string = 'SiO2'\n",
    "    sic_string  = 'SiC' \n",
    "    #materialの設定\n",
    "    S.SetMaterial(Name='Vacuum',Epsilon=1)\n",
    "    S.SetMaterial(Name='Si',Epsilon=3.4**2)\n",
    "    S.SetMaterial(Name='SiO2',Epsilon=1.5**2)\n",
    "    S.SetMaterial(Name='SiC',Epsilon=3.0**2)\n",
    "    S.SetMaterial(Name='PMMA',Epsilon=1.48**2)\n",
    "    S.SetMaterial(Name='Ag',Epsilon=5**2)\n",
    "    S.SetMaterial(Name='HfO2',Epsilon=5**2)\n",
    "    S.SetMaterial(Name='Al2O3',Epsilon=5**2)\n",
    "    S.SetMaterial(Name='Al',Epsilon=5**2)\n",
    "    #レイヤーを設定今回は3つのレイヤー。\n",
    "   \n",
    "        \n",
    "        \n",
    "    S.AddLayer(Name='Level0',Thickness=0.0, Material='Vacuum')\n",
    "    \n",
    "    if(x[(total_layer-4)*2]==0 and x[(total_layer-4)*2+1]==0):\n",
    "        sio2_thick = 0.005\n",
    "    elif(x[(total_layer-4)*2]==0 and x[(total_layer-4)*2+1]==1):\n",
    "        sio2_thick = 0.01\n",
    "    elif(x[(total_layer-4)*2]==1 and x[(total_layer-4)*2+1]==0):\n",
    "        sio2_thick = 0.015\n",
    "    elif(x[(total_layer-4)*2]==1 and x[(total_layer-4)*2+1]==1):\n",
    "        sio2_thick = 0.02\n",
    "\n",
    "    if(x[(total_layer-3)*2]==0 and x[(total_layer-3)*2+1]==0):\n",
    "        ag_thick = 0.005\n",
    "    elif(x[(total_layer-3)*2]==0 and x[(total_layer-3)*2+1]==1):\n",
    "        ag_thick = 0.006\n",
    "    elif(x[(total_layer-3)*2]==1 and x[(total_layer-3)*2+1]==0):\n",
    "        ag_thick = 0.007\n",
    "    elif(x[(total_layer-3)*2]==1 and x[(total_layer-3)*2+1]==1):\n",
    "        ag_thick = 0.008\n",
    "\n",
    "    if(x[(total_layer-2)*2]==0 and x[(total_layer-2)*2+1]==0):\n",
    "        hfo2_thick = 0.005\n",
    "    elif(x[(total_layer-2)*2]==0 and x[(total_layer-2)*2+1]==1):\n",
    "        hfo2_thick = 0.01\n",
    "    elif(x[(total_layer-2)*2]==1 and x[(total_layer-2)*2+1]==0):\n",
    "        hfo2_thick = 0.015\n",
    "    elif(x[(total_layer-2)*2]==1 and x[(total_layer-2)*2+1]==1):\n",
    "        hfo2_thick = 0.02\n",
    "\n",
    "    if(x[(total_layer-1)*2]==0 and x[(total_layer-1)*2+1]==0):\n",
    "        al2o3_thick = 0.005\n",
    "    elif(x[(total_layer-1)*2]==0 and x[(total_layer-1)*2+1]==1):\n",
    "        al2o3_thick = 0.01\n",
    "    elif(x[(total_layer-1)*2]==1 and x[(total_layer-1)*2+1]==0):\n",
    "        al2o3_thick= 0.015\n",
    "    elif(x[(total_layer-1)*2]==1 and x[(total_layer-1)*2+1]==1):\n",
    "        al2o3_thick = 0.02\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    for layercount in range(total_layer-4):\n",
    "        if(x[layercount]==0 and x[layercount+total_layer-4]==0):\n",
    "            S.AddLayer(Name=str(layercount), Thickness=sio2_thick, Material='SiO2')\n",
    "        elif(x[layercount]==0 and x[layercount+total_layer-4]==1):\n",
    "            S.AddLayer(Name=str(layercount), Thickness=ag_thick, Material='Ag')\n",
    "        elif(x[layercount]==1 and x[layercount+total_layer-4]==0):\n",
    "            S.AddLayer(Name=str(layercount), Thickness=hfo2_thick, Material='HfO2')\n",
    "        elif(x[layercount]==1 and x[layercount+total_layer-4]==1):\n",
    "            S.AddLayer(Name=str(layercount), Thickness=al2o3_thick, Material='Al2O3')\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    S.AddLayer(Name='Air',Thickness=0.0,Material='Vacuum')\n",
    "    #S.AddLayerCopy(Name = 'Air', Thickness = 0.0, Layer = 'Level0')\n",
    "    \n",
    "    #波長範囲を設定\n",
    "    wavelength_array=np.linspace(0.4,2,80)\n",
    "    #print(wavelength_array)\n",
    "    wavelength_array_inside = [0.4      , 0.42025316, 0.44050633, 0.46075949, 0.48101266,\n",
    "                               0.50126582, 0.52151899, 0.54177215, 0.56202532, 0.58227848,\n",
    "                               0.60253165, 0.62278481, 0.64303797, 0.66329114, 0.6835443,  0.70379747 ]\n",
    "    wavelength_array_outside1 = [0.72405063 ,0.7443038\n",
    "                                ,0.76455696 ,0.78481013, 0.80506329, 0.82531646, 0.84556962, 0.86582278\n",
    "                                ,0.88607595 ,0.90632911, 0.92658228, 0.94683544, 0.96708861, 0.98734177\n",
    "                                ,1.00759494 ,1.0278481 , 1.04810127, 1.06835443, 1.08860759, 1.10886076\n",
    "                                ,1.12911392 ,1.14936709, 1.16962025, 1.18987342, 1.21012658, 1.23037975\n",
    "                                ,1.25063291 ,1.27088608, 1.29113924, 1.31139241, 1.33164557, 1.35189873\n",
    "                                ,1.3721519  ,1.39240506, 1.41265823, 1.43291139, 1.45316456, 1.47341772\n",
    "                                ,1.49367089 ,1.51392405, 1.53417722, 1.55443038, 1.57468354, 1.59493671\n",
    "                                ,1.61518987 ,1.63544304, 1.6556962 , 1.67594937, 1.69620253, 1.7164557\n",
    "                                ,1.73670886 ,1.75696203, 1.77721519, 1.79746835, 1.81772152, 1.83797468\n",
    "                                ,1.85822785 ,1.87848101, 1.89873418, 1.91898734, 1.93924051, 1.95949367\n",
    "                                ,1.97974684 ,2.0        ]\n",
    "    Planck_array = np.array( [72203 , 100131, 133343, 171499, 214049,\n",
    "                                       260285, 309395, 360519, 412793, 465387,\n",
    "                                       517531, 568535, 617802, 664829, 709210,\n",
    "                                       750632, 788866, 823761, 855234, 883262,\n",
    "                                       907872, 929131, 947141, 962029, 973942,\n",
    "                                       983041, 989499, 993489, 995191, 994782,\n",
    "                                       992435, 988321, 982603, 975436, 966971,\n",
    "                                       957346, 946694, 935139, 922796,\n",
    "                                       909770, 889167, 874851, 860165, 845182,\n",
    "                                       829968, 814583, 799083, 783516, 767926, \n",
    "                                       752353, 736833, 721398, 706074, 690887, \n",
    "                                       675859, 661007, 646350, 631899, 617669,\n",
    "                                       603668, 589905, 576386, 563118, 550104,\n",
    "                                       537348, 524850, 512613, 500637, 488921,\n",
    "                                       477464, 466265, 455321, 444631, 434190,\n",
    "                                       423997, 414047, 404336, 394862, 385619,\n",
    "                                       372180])\n",
    "    Planck_normalized_array = Planck_array#/9.95282\n",
    "    \n",
    "    #効率計算結果用アレイ\n",
    "    efficiency_array=[]\n",
    "    reflected_flux_array = []\n",
    "    emissive_array = []\n",
    "    reflected_flux_array_outside1 = []\n",
    "    reflected_flux_array_outside2 = []\n",
    "    reflected_flux_array_inside = []\n",
    "    efficiency_array_outside = []\n",
    "    reflected_flux_outside  = []\n",
    "    efficiency_array_inside = []\n",
    "    reflected_flux_inside = [] \n",
    "\n",
    "    HfO2_array = [\n",
    "        \n",
    "    ]\n",
    "    Al2O3_array = [\n",
    "        \n",
    "    ]\n",
    "    \n",
    "    SiC_array = [11.959+ 4.7869j\n",
    "    ,11.893+ 4.3625j\n",
    "    ,11.851+ 4.0079j\n",
    "    ,11.816+ 3.6938j\n",
    "    ,11.794+ 3.3971j\n",
    "    ,11.756+ 3.1279j\n",
    "    ,11.714+ 2.8820j\n",
    "    ,11.665+ 2.6576j\n",
    "    ,11.614+ 2.4576j\n",
    "    ,11.561+ 2.2745j\n",
    "    ,11.510+ 2.1070j\n",
    "    ,11.456+ 1.9535j\n",
    "    ,11.393+ 1.8099j\n",
    "    ,11.337+ 1.6870j\n",
    "    ,11.281+ 1.5770j\n",
    "    ,11.227+ 1.4723j\n",
    "    ,11.179+ 1.3799j\n",
    "    ,11.128+ 1.2891j\n",
    "    ,11.082+ 1.2112j\n",
    "    ,11.036+ 1.1316j\n",
    "    ,10.982+ 1.0604j\n",
    "    ,10.932+ 1.0079j\n",
    "    ,10.898+ 0.9507j\n",
    "    ,10.846+ 0.9045j\n",
    "    ,10.815+ 0.8471j\n",
    "    ,10.776+ 0.8223j\n",
    "    ,10.759+ 0.7672j\n",
    "    ,10.726+ 0.7301j\n",
    "    ,10.689+ 0.6723j\n",
    "    ,10.655+ 0.6473j\n",
    "    ,10.620+ 0.6224j\n",
    "    ,10.586+ 0.5976j\n",
    "    ,10.552+ 0.5728j\n",
    "    ,10.525+ 0.5513j\n",
    "    ,10.504+ 0.5325j\n",
    "    ,10.483+ 0.5137j\n",
    "    ,10.462+ 0.4949j\n",
    "    ,10.441+ 0.4762j\n",
    "    ,10.420+ 0.4575j\n",
    "    ,10.403+ 0.4402j\n",
    "    ,10.378+ 0.4150j\n",
    "    ,10.362+ 0.3983j\n",
    "    ,10.346+ 0.3816j\n",
    "    ,10.330+ 0.3649j\n",
    "    ,10.313+ 0.3483j\n",
    "    ,10.297+ 0.3317j\n",
    "    ,10.283+ 0.3206j\n",
    "    ,10.269+ 0.3098j\n",
    "    ,10.256+ 0.2990j\n",
    "    ,10.242+ 0.2882j\n",
    "    ,10.228+ 0.2774j\n",
    "    ,10.214+ 0.2667j\n",
    "    ,10.201+ 0.2559j\n",
    "    ,10.187+ 0.2452j\n",
    "    ,10.173+ 0.2345j\n",
    "    ,10.161+ 0.2262j\n",
    "    ,10.151+ 0.2197j\n",
    "    ,10.141+ 0.2132j\n",
    "    ,10.131+ 0.2068j\n",
    "    ,10.121+ 0.2003j\n",
    "    ,10.111+ 0.1939j\n",
    "    ,10.101+ 0.1874j\n",
    "    ,10.091+ 0.1810j\n",
    "    ,10.081+ 0.1746j\n",
    "    ,10.071+ 0.1682j\n",
    "    ,10.061+ 0.1618j\n",
    "    ,10.051+ 0.1554j\n",
    "    ,10.041+ 0.1491j\n",
    "    ,10.032+ 0.1438j\n",
    "    ,10.023+ 0.1385j\n",
    "    ,10.014+ 0.1333j\n",
    "    ,10.006+ 0.1280j\n",
    "    ,9.9969+ 0.1227j\n",
    "    ,9.9881+ 0.1175j\n",
    "    ,9.9794+ 0.1123j\n",
    "    ,9.9711+ 0.1084j\n",
    "    ,9.9631+ 0.1052j\n",
    "    ,9.9552+ 0.1020j\n",
    "    ,9.9472+ 0.0988j\n",
    "    ,9.9352+ 0.0941j ]\n",
    "\n",
    "\n",
    "    \n",
    "    Ag_array= [-4.5730+0.23090j\n",
    "    ,-5.6067+0.23916j\n",
    "    ,-6.6569+0.26761j\n",
    "    ,-7.7231+0.28956j\n",
    "    ,-8.8055+0.31331j\n",
    "    ,-9.9352+0.32785j\n",
    "    ,-11.090+0.34592j\n",
    "    ,-12.289+0.36117j\n",
    "    ,-13.543+0.36946j\n",
    "    ,-14.821+0.38399j\n",
    "    ,-16.151+0.39432j\n",
    "    ,-17.535+0.40347j\n",
    "    ,-18.957+0.42822j\n",
    "    ,-20.420+0.45177j\n",
    "    ,-21.924+0.47418j\n",
    "    ,-23.468+0.49476j\n",
    "    ,-25.059+0.51481j\n",
    "    ,-26.693+0.53629j\n",
    "    ,-28.375+0.55852j\n",
    "    ,-30.100+0.58312j\n",
    "    ,-31.866+0.61038j\n",
    "    ,-33.683+0.63822j\n",
    "    ,-35.549+0.67139j\n",
    "    ,-37.465+0.70572j\n",
    "    ,-39.431+0.74107j\n",
    "    ,-41.420+0.78426j\n",
    "    ,-43.458+0.82865j\n",
    "    ,-45.545+0.87425j\n",
    "    ,-47.674+0.92080j\n",
    "    ,-49.850+0.96840j\n",
    "    ,-52.074+ 1.0172j\n",
    "    ,-53.460+ 1.0477j\n",
    "    ,-55.726+ 1.1005j\n",
    "    ,-58.023+ 1.1600j\n",
    "    ,-60.367+ 1.2209j\n",
    "    ,-62.757+ 1.2833j\n",
    "    ,-65.194+ 1.3472j\n",
    "    ,-67.662+ 1.4124j\n",
    "    ,-70.16 + 1.4790j\n",
    "    ,-72.720+ 1.5471j\n",
    "    ,-76.633+ 1.6519j\n",
    "    ,-79.299+ 1.7237j\n",
    "    ,-82.011+ 1.7961j\n",
    "    ,-84.770+ 1.8692j\n",
    "    ,-87.574+ 1.9437j\n",
    "    ,-90.417+ 2.0197j\n",
    "    ,-93.284+ 2.0975j\n",
    "    ,-96.196+ 2.1768j\n",
    "    ,-99.152+ 2.2574j\n",
    "    ,-102.17+ 2.3447j\n",
    "    ,-105.25+ 2.4370j\n",
    "    ,-108.37+ 2.5310j\n",
    "    ,-111.54+ 2.6267j\n",
    "    ,-114.74+ 2.7251j\n",
    "    ,-117.96+ 2.8261j\n",
    "    ,-121.23+ 2.9289j\n",
    "    ,-124.54+ 3.0334j\n",
    "    ,-127.90+ 3.1397j\n",
    "    ,-131.30+ 3.2501j\n",
    "    ,-134.75+ 3.3624j\n",
    "    ,-138.24+ 3.4765j\n",
    "    ,-141.78+ 3.5924j\n",
    "    ,-145.36+ 3.7101j\n",
    "    ,-149.02+ 3.8350j\n",
    "    ,-152.72+ 3.9628j\n",
    "    ,-156.47+ 4.0926j\n",
    "    ,-160.27+ 4.2244j\n",
    "    ,-164.11+ 4.3581j\n",
    "    ,-168.00+ 4.4938j\n",
    "    ,-171.87+ 4.6422j\n",
    "    ,-175.79+ 4.7935j\n",
    "    ,-179.74+ 4.9470j\n",
    "    ,-183.75+ 5.1026j\n",
    "    ,-187.80+ 5.2605j\n",
    "    ,-191.89+ 5.4206j\n",
    "    ,-196.02+ 5.5846j\n",
    "    ,-200.20+ 5.7602j\n",
    "    ,-204.42+ 5.9382j\n",
    "    ,-208.69+ 6.1187j\n",
    "    ,-215.17+ 6.3940j]\n",
    "    \n",
    "    SiO2_array =[2.2025+0.0j\n",
    "    ,2.1968+0.0j\n",
    "    ,2.1920+0.0j\n",
    "    ,2.1878+0.0j\n",
    "    ,2.1841+0.0j\n",
    "    ,2.1809+0.0j\n",
    "    ,2.1781+0.0j           \n",
    "    ,2.1755+0.0j          \n",
    "    ,2.1733+0.0j          \n",
    "    ,2.1713+0.0j\n",
    "    ,2.1695+0.0j\n",
    "    ,2.1679+0.0j\n",
    "    ,2.1664+0.0j\n",
    "    ,2.1650+0.0j\n",
    "    ,2.1638+0.0j\n",
    "    ,2.1627+0.0j\n",
    "    ,2.1617+0.0j\n",
    "    ,2.1608+0.0j\n",
    "    ,2.1599+0.0j\n",
    "    ,2.1591+0.0j\n",
    "    ,2.1584+0.0j\n",
    "    ,2.1577+0.0j\n",
    "    ,2.1571+0.0j\n",
    "    ,2.1565+0.0j\n",
    "    ,2.1559+0.0j\n",
    "    ,2.1553+0.0j\n",
    "    ,2.1547+0.0j\n",
    "    ,2.1541+0.0j\n",
    "    ,2.1535+0.0j\n",
    "    ,2.1529+0.0j\n",
    "    ,2.1523+0.0j\n",
    "    ,2.1517+0.0j\n",
    "    ,2.1511+0.0j\n",
    "    ,2.1505+0.0j\n",
    "    ,2.1499+0.0j\n",
    "    ,2.1493+0.0j\n",
    "    ,2.1487+0.0j\n",
    "    ,2.1481+0.0j\n",
    "    ,2.1475+0.0j\n",
    "    ,2.1471+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j ] \n",
    "    \n",
    "    Al_array= [-23.144+4.7182j\n",
    "    ,-25.589+5.5127j\n",
    "    ,-28.145+6.4195j\n",
    "    ,-30.731+7.4949j\n",
    "    ,-33.395+8.6579j\n",
    "    ,-36.090+9.9091j\n",
    "    ,-38.872+11.265j\n",
    "    ,-41.710+12.807j\n",
    "    ,-44.643+14.429j\n",
    "    ,-47.493+16.359j\n",
    "    ,-50.406+18.401j\n",
    "    ,-53.354+20.582j\n",
    "    ,-56.098+23.131j\n",
    "    ,-58.640+25.854j\n",
    "    ,-60.999+28.736j\n",
    "    ,-62.933+31.901j\n",
    "    ,-64.704+35.228j\n",
    "    ,-65.238+38.813j\n",
    "    ,-65.274+42.509j\n",
    "    ,-63.977+45.423j\n",
    "    ,-61.615+46.062j\n",
    "    ,-60.201+45.005j\n",
    "    ,-59.941+42.950j\n",
    "    ,-60.318+39.930j\n",
    "    ,-60.709+36.927j\n",
    "    ,-64.186+33.671j\n",
    "    ,-68.333+30.708j\n",
    "    ,-73.343+28.403j\n",
    "    ,-79.497+27.064j\n",
    "    ,-84.779+27.151j\n",
    "    ,-89.852+27.369j\n",
    "    ,-94.605+27.627j\n",
    "    ,-99.324+27.942j\n",
    "    ,-104.10+28.269j\n",
    "    ,-108.98+28.581j\n",
    "    ,-113.97+28.880j\n",
    "    ,-119.06+29.192j\n",
    "    ,-124.15+29.750j\n",
    "    ,-129.35+30.306j\n",
    "    ,-134.66+30.861j\n",
    "    ,-140.07+31.413j\n",
    "    ,-145.58+31.964j\n",
    "    ,-151.15+32.680j\n",
    "    ,-156.77+33.553j\n",
    "    ,-162.49+34.436j\n",
    "    ,-168.31+35.329j\n",
    "    ,-174.24+36.232j\n",
    "    ,-180.27+37.144j\n",
    "    ,-186.40+38.067j\n",
    "    ,-192.48+39.216j\n",
    "    ,-198.61+40.462j\n",
    "    ,-204.83+41.728j\n",
    "    ,-211.15+43.014j\n",
    "    ,-217.57+44.319j\n",
    "    ,-224.08+45.644j\n",
    "    ,-230.68+46.988j\n",
    "    ,-237.38+48.351j\n",
    "    ,-244.13+49.796j\n",
    "    ,-250.78+51.470j\n",
    "    ,-257.53+53.171j\n",
    "    ,-264.36+54.898j\n",
    "    ,-271.28+56.653j\n",
    "    ,-278.29+58.434j\n",
    "    ,-285.39+60.242j\n",
    "    ,-292.58+62.077j\n",
    "    ,-299.86+63.938j\n",
    "    ,-307.23+65.826j\n",
    "    ,-314.69+67.741j\n",
    "    ,-322.14+69.745j\n",
    "    ,-329.44+71.924j\n",
    "    ,-336.83+74.134j\n",
    "    ,-344.29+76.375j\n",
    "    ,-351.84+78.647j\n",
    "    ,-359.47+80.951j\n",
    "    ,-367.18+83.286j\n",
    "    ,-374.97+85.652j\n",
    "    ,-382.84+88.049j\n",
    "    ,-390.79+90.477j\n",
    "    ,-398.83+92.936j\n",
    "    ,-406.95+95.427j    ]\n",
    "    SiO2_array_index = 0\n",
    "    SiC_array_index = 0\n",
    "    Ag_array_index = 0\n",
    "    HfO2_array_index = 0\n",
    "    Al2O3_array_index = 0\n",
    "    Al_array_index = 0\n",
    "    Planck_normalized_array_index = 0\n",
    "    for wavelength in wavelength_array:\n",
    "       \n",
    "        S.SetMaterial(Name='SiO2',Epsilon=SiO2_array[SiO2_array_index])\n",
    "        SiO2_array_index = SiO2_array_index + 1\n",
    "        S.SetMaterial(Name='SiC',Epsilon=SiC_array[SiC_array_index])\n",
    "        SiC_array_index = SiC_array_index + 1\n",
    "        S.SetMaterial(Name='Ag',Epsilon=Ag_array[Ag_array_index])\n",
    "        Ag_array_index = Ag_array_index + 1\n",
    "        S.SetMaterial(Name='HfO2',Epsilon=n_hfo2(wavelength))\n",
    "        HfO2_array_index = HfO2_array_index + 1\n",
    "        S.SetMaterial(Name='Al2O3',Epsilon=n_al2o3(wavelength))\n",
    "        Al2O3_array_index = Al2O3_array_index + 1\n",
    "        S.SetMaterial(Name='Al',Epsilon=Al_array[Al_array_index])\n",
    "        Al_array_index = Al_array_index + 1\n",
    "        S.SetFrequency((1/wavelength))\n",
    "    \n",
    "        #入射角0度のs偏光平面波を入射する。\n",
    "        S.SetExcitationPlanewave(IncidenceAngles=(0,0),sAmplitude=0,pAmplitude=1)\n",
    "        \n",
    "        #入射フラックスを取得\n",
    "        (P_incident,P_reflect)=S.GetPowerFlux(Layer='Level0')\n",
    "        \n",
    "        #各次数の透過フラックスを取得\n",
    "        #P_transmittance=S.GetPowerFluxByOrder(Layer='Air')\n",
    "        (P_air_transmittance,P_air_reflect) =S.GetPowerFlux(Layer='Air')\n",
    "        #1次回折光の効率になおす。\n",
    "        #efficiency=(P_transmittance[1][0]/P_incident).real\n",
    "        #Note that efficiency => transmittance\n",
    "        efficiency=(P_air_transmittance/P_incident).real\n",
    "        #efficiency=-(P_reflect/P_incident).real\n",
    "        #アレイに追加。\n",
    "        efficiency_array.append(efficiency)\n",
    "        reflected_flux = (-(P_reflect/P_incident)).real\n",
    "        reflected_flux_array.append(reflected_flux)\n",
    "        #emissive = (1-((P_incident + P_reflect - P_air_transmittance)/P_incident)).real\n",
    "        emissive = (1 - efficiency - reflected_flux )\n",
    "        #emissive = ( efficiency)\n",
    "        emissive_array.append(emissive)\n",
    "        \n",
    "        if(0.71<=wavelength<=2):\n",
    "            reflected_flux_array_outside1.append((emissive)*Planck_normalized_array[Planck_normalized_array_index])\n",
    "            efficiency_array_outside.append(efficiency)\n",
    "            reflected_flux_outside.append(reflected_flux)\n",
    "        elif(0<wavelength<0.71):\n",
    "            reflected_flux_array_inside.append((emissive)*Planck_normalized_array[Planck_normalized_array_index])\n",
    "            efficiency_array_inside.append(efficiency)\n",
    "            reflected_flux_inside.append(reflected_flux)\n",
    "            \n",
    "        Planck_normalized_array_index = Planck_normalized_array_index +1\n",
    "        #進捗表示。\n",
    "        #sys.stdout.write(f\"\\r wavelength={wavelength} eff={emissive}\")\n",
    "        #sys.stdout.flush()\n",
    "    \n",
    "    #matplotlibで表示\n",
    "    if(print_spectrum):\n",
    "        plt.grid()\n",
    "        plt.xlabel('wavelength [μm]')\n",
    "        plt.ylabel('transmittance reflectance absorbance')\n",
    "        plt.vlines(x = 0.4, ymin = 0, ymax = 1, colors = 'purple',linestyle='dashed')\n",
    "        plt.vlines(x = 0.7, ymin = 0, ymax = 1, colors = 'red',linestyle='dashed')\n",
    "        plt.plot(wavelength_array,efficiency_array , label = 'transmittance')\n",
    "        plt.plot(wavelength_array,reflected_flux_array, label = 'reflectance')\n",
    "        plt.plot(wavelength_array,emissive_array, label = 'absorbance')\n",
    "        plt.xlim([0.4,2])\n",
    "        plt.ylim([0,1])\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    planck_1_8 = 20.5066#/9.95282\n",
    "    planck_8_13 = 47.1002#/9.95282\n",
    "    planck_13_20 = 40.2612#/9.95282\n",
    "    planck_inside =  120571\n",
    "    planck_outside = 954989 \n",
    "    planck_all_window = integrate.simps(Planck_normalized_array, wavelength_array)\n",
    "    all_window = integrate.simps(emissive_array, wavelength_array)\n",
    "    insidewindows = integrate.simps(reflected_flux_array_inside, wavelength_array_inside)\n",
    "    outsidewindows1 = integrate.simps(reflected_flux_array_outside1, wavelength_array_outside1)\n",
    "    \n",
    "    insidewindows_T = integrate.simps(efficiency_array_inside, wavelength_array_inside)\n",
    "    outsidewindows1_T = integrate.simps(efficiency_array_outside, wavelength_array_outside1)\n",
    "    insidewindows_R = integrate.simps(reflected_flux_inside, wavelength_array_inside)\n",
    "    outsidewindows1_R = integrate.simps(reflected_flux_outside, wavelength_array_outside1)\n",
    "    if(print_TR_percent):\n",
    "        print(insidewindows_T/0.303 )\n",
    "        print(outsidewindows1_R/1.297)\n",
    "    return (-(insidewindows_T/0.303 - outsidewindows1_T/1.297+ outsidewindows1_R/1.297 - insidewindows_R/0.303))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c2d3696-9aa6-4178-9660-3714cfa2f9af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T09:11:28.259736Z",
     "iopub.status.busy": "2025-04-23T09:11:28.259488Z",
     "iopub.status.idle": "2025-04-23T09:11:28.267035Z",
     "shell.execute_reply": "2025-04-23T09:11:28.265977Z"
    },
    "papermill": {
     "duration": 0.031577,
     "end_time": "2025-04-23T09:11:28.269459",
     "exception": false,
     "start_time": "2025-04-23T09:11:28.237882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_unique_binary_array(init_dataset_size, rings):\n",
    "    # Calculate maximum possible unique rows\n",
    "    max_unique = 2 ** rings\n",
    "    \n",
    "    if init_dataset_size > max_unique:\n",
    "        raise ValueError(f\"Cannot generate {init_dataset_size} unique rows with only {rings} bits. Maximum is {max_unique}.\")\n",
    "    \n",
    "    # Generate all possible binary combinations\n",
    "    if rings <= 20:  # For reasonable memory usage\n",
    "        all_combinations = np.array(\n",
    "            [list(np.binary_repr(i, width=rings)) for i in range(max_unique)],\n",
    "            dtype=np.int8\n",
    "        )\n",
    "    else:\n",
    "        # For large rings, generate random combinations until we have enough\n",
    "        # This is less efficient but works for large rings\n",
    "        unique_rows = set()\n",
    "        while len(unique_rows) < init_dataset_size:\n",
    "            new_row = np.random.randint(0, 2, size=rings, dtype=np.int8)\n",
    "            unique_rows.add(tuple(new_row))\n",
    "        all_combinations = np.array(list(unique_rows), dtype=np.int8)\n",
    "    \n",
    "    # Randomly select the required number of unique rows\n",
    "    if init_dataset_size < max_unique:\n",
    "        selected_indices = np.random.choice(max_unique, size=init_dataset_size, replace=False)\n",
    "        result = all_combinations[selected_indices]\n",
    "    else:\n",
    "        result = all_combinations\n",
    "    \n",
    "    # Shuffle the rows\n",
    "    np.random.shuffle(result)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9298fc52-19e5-4b69-8c26-a15384ba4126",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T09:11:28.310544Z",
     "iopub.status.busy": "2025-04-23T09:11:28.310205Z",
     "iopub.status.idle": "2025-04-23T09:11:28.317649Z",
     "shell.execute_reply": "2025-04-23T09:11:28.316401Z"
    },
    "papermill": {
     "duration": 0.028457,
     "end_time": "2025-04-23T09:11:28.319478",
     "exception": false,
     "start_time": "2025-04-23T09:11:28.291021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def foms_calc(\n",
    "        configs=np.array([], dtype=np.int8),\n",
    "        target=None,\n",
    "        save_data=True,\n",
    "        save_fig=False\n",
    "    ):\n",
    "\n",
    "    \"\"\"\n",
    "    用途：計算configs對應的foms，並儲存計算出的foms到檔案\n",
    "\n",
    "    輸入參數\n",
    "    - configs\n",
    "    - target\n",
    "    - save_data\n",
    "    - save_fig\n",
    "\n",
    "    返回值\n",
    "    - foms : [configs.shape[0]]\n",
    "    \"\"\"\n",
    "    \n",
    "    foms = np.zeros(configs.shape[0])\n",
    "    \n",
    "    #obj_zp = ZonePlate(resolution=resolution)\n",
    "    for i in range(configs.shape[0]):\n",
    "        #obj_zp.set_config(configs[i])\n",
    "        foms[i] = s4_multilayer_FOM(configs[i])\n",
    "\n",
    "    return foms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c2afc7a-d949-481a-b581-b81e2ef70d04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T09:11:28.349857Z",
     "iopub.status.busy": "2025-04-23T09:11:28.348500Z",
     "iopub.status.idle": "2025-04-23T09:11:28.364742Z",
     "shell.execute_reply": "2025-04-23T09:11:28.363063Z"
    },
    "papermill": {
     "duration": 0.034117,
     "end_time": "2025-04-23T09:11:28.367184",
     "exception": false,
     "start_time": "2025-04-23T09:11:28.333067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_file(configs, foms, path=None):\n",
    "    \"\"\"\n",
    "    用途：將configs跟foms儲存到對應的路徑\n",
    "\n",
    "    參數：\n",
    "    - configs\n",
    "    - foms\n",
    "    - path    : 完整的路徑\n",
    "    \"\"\"\n",
    "    \n",
    "    folder_name, file_name = os.path.split(path)\n",
    "\n",
    "    # 沒有folder的話就先建folder\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    \n",
    "    # 將要存的數據存為pandas dataframe的格式\n",
    "    headers = [f\"ring{i+1}\" for i in range(configs[0].size)]\n",
    "    df = pd.DataFrame(data=configs, dtype=np.int8, columns=headers)\n",
    "    df[\"FOM\"] = foms\n",
    "    \n",
    "    # 開啟/建立檔案，使用append模式\n",
    "    if os.path.exists(path):\n",
    "        df.to_csv(path, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        df.to_csv(path, header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5f7f215-e952-4807-80ee-94d7de4f80be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T09:11:28.396885Z",
     "iopub.status.busy": "2025-04-23T09:11:28.396087Z",
     "iopub.status.idle": "2025-04-23T09:11:28.439899Z",
     "shell.execute_reply": "2025-04-23T09:11:28.438297Z"
    },
    "papermill": {
     "duration": 0.061909,
     "end_time": "2025-04-23T09:11:28.442429",
     "exception": false,
     "start_time": "2025-04-23T09:11:28.380520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_file(method=None, n=None, k=None, thresh=None, repeat=False, path=None):\n",
    "    \"\"\"\n",
    "    - read_all          : 全部讀取\n",
    "    - read_n            : 隨機讀n筆\n",
    "    - read_top_n        : 照順序讀前n筆\n",
    "    - read_fom_top_n    : 照FOM由小到大的順序讀前n筆\n",
    "    - read_fom_top_x_k  : 隨機抽x筆，取FOM為前k%的數據，輸出的筆數是n\n",
    "    - read_n_thresh_fom : 隨機讀n筆FOM小於某個值的數據（很可能達不到n筆，那就看要不要重複取）\n",
    "\n",
    "    先實現：read_n, read_fom_top_x_k, read_n_thresh_fom\n",
    "    除了read_all，其他都是輸出n筆資料\n",
    "    \"\"\"\n",
    "\n",
    "    # 預處理\n",
    "    if (not os.path.exists(path)) or (not os.path.isfile(path)):    # path的正確性\n",
    "        raise FileNotFoundError(f\"檔案不存在 or 此路徑不是檔案： {path}\")\n",
    "    with open(path) as f:    # 計算檔案的總rows數（不含header的row）\n",
    "        total_rows = sum(1 for _ in f) - 1\n",
    "    if n > total_rows:    # 讀取筆數的正確性\n",
    "        raise ValueError(\"檔案沒有那麼多筆資料可以取\")\n",
    "\n",
    "    # 實現讀檔方式\n",
    "    if (method == \"read_all\"):\n",
    "        df = pd.read_csv(path)\n",
    "        configs = df.iloc[:, :-1].values.astype(np.int8)\n",
    "        foms    = df.iloc[:, -1].values.astype(np.float64)\n",
    "    \n",
    "    elif (method == \"read_n\"):\n",
    "        \"\"\"隨機讀n筆\"\"\"\n",
    "        rows_to_read = random.sample(range(1, total_rows + 1), n)\n",
    "        df = pd.read_csv(path, skiprows=lambda x: x > 0 and x not in [0] + rows_to_read, header=0)\n",
    "        df = df.sample(frac=1, random_state=None).reset_index(drop=True)\n",
    "        \n",
    "        configs = df.iloc[:, :-1].values.astype(np.int8)\n",
    "        foms    = df.iloc[:, -1].values.astype(np.float64)\n",
    "        \n",
    "    elif (method == \"read_top_n\"):\n",
    "        pass\n",
    "    \n",
    "    elif (method == \"read_fom_top_n\"):\n",
    "        pass\n",
    "        \n",
    "    elif (method == \"read_fom_top_x_k\"):\n",
    "        \"\"\"隨機抽n筆，取FOM為前k%的數據\"\"\"\n",
    "        \n",
    "    elif (method == \"read_n_thresh_fom\"):\n",
    "        \"\"\"隨機讀n筆FOM小於某個值的數據（很可能達不到n筆，那就看要不要重複取）\"\"\"\n",
    "\n",
    "        chunksize = 100    # 測試調整\n",
    "        reservoir = []        # 儲存候選抽樣資料（最多 n 筆）\n",
    "        candidate_count = 0   # 紀錄符合條件的候選筆數\n",
    "    \n",
    "        # 使用 chunksize 逐塊讀取 CSV 檔案\n",
    "        for chunk in pd.read_csv(path, chunksize=chunksize, header=None):\n",
    "            # 假設最後一欄是數值，利用 iloc 取得最後一欄，再做條件過濾\n",
    "            chunk.iloc[:, -1] = pd.to_numeric(chunk.iloc[:, -1], errors='coerce')\n",
    "            filtered_chunk = chunk[chunk.iloc[:, -1].astype(float) <= thresh]\n",
    "            \n",
    "            # 逐筆處理過濾後的資料\n",
    "            for row in filtered_chunk.itertuples(index=False, name=None):\n",
    "                candidate_count += 1\n",
    "                if candidate_count <= n:\n",
    "                    reservoir.append(row)\n",
    "                else:\n",
    "                    # Reservoir Sampling：以 n/candidate_count 的機率取代現有項目\n",
    "                    r = random.randint(1, candidate_count)\n",
    "                    if r <= n:\n",
    "                        reservoir[r - 1] = row\n",
    "\n",
    "        # 沒有小於thresh的FOM\n",
    "        if (not reservoir):\n",
    "            print(f\"沒有小於{thresh}的FOM\")\n",
    "            sys.exit(1)\n",
    "        \n",
    "        # 如果候選筆數不足 n 筆，根據 repeat 參數處理\n",
    "        if candidate_count < n:\n",
    "            if repeat and reservoir:\n",
    "                while len(reservoir) < n:\n",
    "                    reservoir.append(random.choice(reservoir))\n",
    "            # 若 repeat 為 False，就僅回傳現有候選資料\n",
    "\n",
    "        # 後處理\n",
    "        configs_ls = [t[:-1] for t in reservoir]\n",
    "        foms_ls    = [t[-1] for t in reservoir]\n",
    "        configs = np.array(configs_ls, dtype=np.int8)\n",
    "        foms    = np.array(foms_ls, dtype=np.float64)\n",
    "\n",
    "    else:\n",
    "        print(f\"未定義{method}讀檔方法\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    # 返回讀檔結果\n",
    "    return configs, foms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c93506c-8d11-492b-ace3-a0377da864f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T09:11:28.474181Z",
     "iopub.status.busy": "2025-04-23T09:11:28.473368Z",
     "iopub.status.idle": "2025-04-23T09:11:28.484073Z",
     "shell.execute_reply": "2025-04-23T09:11:28.482463Z"
    },
    "papermill": {
     "duration": 0.029461,
     "end_time": "2025-04-23T09:11:28.486277",
     "exception": false,
     "start_time": "2025-04-23T09:11:28.456816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def num_reads_adds_generator(dataset_size, num_adds_ratio, num_reads_ratio, num_adds_limit):\n",
    "    \"\"\"\n",
    "    Purpose: Define the quantity of num_reads and num_adds (for dynamic_sampling)\n",
    "    \n",
    "    參數\n",
    "    - dataset_size: dataset總共有幾筆數據\n",
    "    \"\"\"\n",
    "    num_adds = int(dataset_size * num_adds_ratio)\n",
    "    if num_adds > num_adds_limit:\n",
    "        num_adds = num_adds_limit\n",
    "    num_reads = num_adds * num_reads_ratio\n",
    "    return num_adds, num_reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d24a3db9-891e-490b-aecc-8a89dda55883",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T09:11:28.518712Z",
     "iopub.status.busy": "2025-04-23T09:11:28.517921Z",
     "iopub.status.idle": "2025-04-23T09:11:28.542677Z",
     "shell.execute_reply": "2025-04-23T09:11:28.540931Z"
    },
    "papermill": {
     "duration": 0.044274,
     "end_time": "2025-04-23T09:11:28.545236",
     "exception": false,
     "start_time": "2025-04-23T09:11:28.500962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_new_data(add_method, sampleset, num_adds, **kwargs):\n",
    "    \"\"\"\n",
    "    Purpose: Return the new data to be added to the training set and the testing set (use after sampling)\n",
    "\n",
    "    Provided Methods\n",
    "    - min_fom\n",
    "    - min_energy\n",
    "    - min_fom_with_flip\n",
    "    - min_energy_with_flip\n",
    "\n",
    "    Parameters\n",
    "    - add_method : The method of adding new data (see the provided methods above)\n",
    "    - sampleset  : (use the attribute record[\"sample\"] to extract the configs; use the attribute record[\"energy\"] to extract the energies)\n",
    "    - num_adds   : \n",
    "    - **kwargs   : {\"resolution\", \"multiple\", \"target\"} -> pass to the function \"foms_calc\"\n",
    "\n",
    "    Return\n",
    "    - new_configs, new_energies, new_foms -> Randomized order\n",
    "    \"\"\"\n",
    "\n",
    "    # Preprocessing\n",
    "    resolution = kwargs.get(\"resolution\")\n",
    "    multiple   = kwargs.get(\"multiple\")\n",
    "    target     = kwargs.get(\"target\")\n",
    "    if (add_method != \"min_fom\") and (add_method != \"min_energy\") and \\\n",
    "       (add_method != \"min_fom_with_flip\") and (add_method != \"min_energy_with_flip\"):\n",
    "        print(f\"No providing this adding method：{add_method}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Implementation of each adding method\n",
    "    if add_method == \"min_fom\":\n",
    "        foms_sampled = foms_calc(sampleset.record[\"sample\"], resolution, multiple, target)\n",
    "        adds_indices = np.argsort(foms_sampled)[:num_adds]\n",
    "        new_configs  = sampleset.record[\"sample\"][adds_indices]\n",
    "        new_energies = sampleset.record[\"energy\"][adds_indices]\n",
    "        new_foms     = foms_sampled[adds_indices]\n",
    "    \n",
    "    elif add_method == \"min_energy\":\n",
    "        adds_indices = np.argsort(sampleset.record[\"energy\"])[:num_adds]\n",
    "        new_configs  = sampleset.record[\"sample\"][adds_indices]\n",
    "        new_energies = sampleset.record[\"energy\"][adds_indices]\n",
    "        new_foms     = foms_calc(new_configs, resolution, multiple, target)\n",
    "\n",
    "    elif add_method == \"min_fom_with_flip\":\n",
    "        pass\n",
    "\n",
    "    elif add_method == \"min_energy_with_flip\":\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        print(\"Some issues in the function \\\"add_new_data\\\"\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Randomize the order\n",
    "    shuffled_indices = np.random.permutation(new_configs.shape[0])\n",
    "    new_configs  = new_configs[shuffled_indices]\n",
    "    new_energies = new_energies[shuffled_indices]\n",
    "    new_foms     = new_foms[shuffled_indices]\n",
    "    \n",
    "    return new_configs, new_energies, new_foms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "915c68a4-456d-4053-9a1f-bddc9b1e5936",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T09:11:28.576140Z",
     "iopub.status.busy": "2025-04-23T09:11:28.575345Z",
     "iopub.status.idle": "2025-04-23T09:11:28.590628Z",
     "shell.execute_reply": "2025-04-23T09:11:28.588950Z"
    },
    "papermill": {
     "duration": 0.033946,
     "end_time": "2025-04-23T09:11:28.593135",
     "exception": false,
     "start_time": "2025-04-23T09:11:28.559189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sort_new_data(sort_method, new_configs, new_energies, new_foms):\n",
    "    \"\"\"\n",
    "    Purpose: Sort the new data (use after calling add_new_data)\n",
    "\n",
    "    Provided Method\n",
    "    - fom_ascent\n",
    "    - energy_ascent\n",
    "\n",
    "    Return\n",
    "    - new_configs, new_energies, new_foms -> Sorted order\n",
    "    \"\"\"\n",
    "\n",
    "    # Preprocessing\n",
    "    if (sort_method != \"fom_ascent\") and (sort_method != \"energy_ascent\"):\n",
    "        print(f\"No providing this adding method：{add_method}\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    if sort_method == \"fom_ascent\":\n",
    "        sorted_indices = np.argsort(new_foms)\n",
    "    elif sort_method == \"energy_ascent\":\n",
    "        sorted_indices = np.argsort(new_energies)\n",
    "    else:\n",
    "        print(\"Some issues in the function \\\"sort_new_data\\\"\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    new_configs  = new_configs[sorted_indices]\n",
    "    new_energies = new_energies[sorted_indices]\n",
    "    new_foms     = new_foms[sorted_indices]\n",
    "    \n",
    "    return new_configs, new_energies, new_foms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0859b827-494c-4e98-b285-1b6bdbfc4260",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T09:11:28.625949Z",
     "iopub.status.busy": "2025-04-23T09:11:28.625138Z",
     "iopub.status.idle": "2025-04-23T09:11:28.637518Z",
     "shell.execute_reply": "2025-04-23T09:11:28.635837Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.031612,
     "end_time": "2025-04-23T09:11:28.639923",
     "exception": false,
     "start_time": "2025-04-23T09:11:28.608311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_indices(base, arr):\n",
    "    # 先確認 arr 的所有元素都存在於 base\n",
    "    if not np.all(np.isin(arr, base)):\n",
    "        raise ValueError(\"arr contains elements not found in base\")\n",
    "\n",
    "    # 對 base 進行排序並記錄原始索引\n",
    "    sorted_idx = np.argsort(base)  # base 排序後的索引\n",
    "    sorted_base = base[sorted_idx]  # 排序後的 base\n",
    "\n",
    "    # 使用 searchsorted 找到 arr 在排序後 base 的索引\n",
    "    sorted_positions = np.searchsorted(sorted_base, arr)\n",
    "\n",
    "    # 轉換回原始 base 的索引\n",
    "    original_indices = sorted_idx[sorted_positions]\n",
    "\n",
    "    return original_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9be42883-3604-4419-ad16-4f69cd0c99c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T09:11:28.670907Z",
     "iopub.status.busy": "2025-04-23T09:11:28.670122Z",
     "iopub.status.idle": "2025-04-23T09:11:28.718414Z",
     "shell.execute_reply": "2025-04-23T09:11:28.716747Z"
    },
    "papermill": {
     "duration": 0.067124,
     "end_time": "2025-04-23T09:11:28.720971",
     "exception": false,
     "start_time": "2025-04-23T09:11:28.653847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_foms(foms=None, split_idx=None, original=True, modified=True, show=False, save=True, path=\"fom_i-th_config.png\"):\n",
    "    \"\"\"\n",
    "    用途：畫foms與modified_foms的圖\n",
    "\n",
    "    參數：\n",
    "      - foms      : numpy 陣列，代表多個 zone plates 各組態的 FOM 值\n",
    "      - split_idx : 分隔 training set 的索引（若提供則在圖中顯示分隔線）\n",
    "      - original  : 是否繪製原始 FOM 的圖\n",
    "      - modified  : 是否繪製修改後 FOM 的圖\n",
    "      - show      : 是否顯示圖形\n",
    "      - save      : 是否儲存圖形\n",
    "      - path      : 儲存圖形的檔案路徑\n",
    "    \"\"\"\n",
    "\n",
    "    if foms is None:\n",
    "        print(\"沒有提供 FOM 資料！\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # 計算修改後的 FOM：若後一筆 FOM 大於前一筆，則改成前一筆的值\n",
    "    foms_modified = foms.copy()\n",
    "    for i in range(foms_modified.shape[0] - 1):\n",
    "        if foms_modified[i + 1] > foms_modified[i]:\n",
    "            foms_modified[i + 1] = foms_modified[i]\n",
    "\n",
    "    # 確認至少有一個圖需要繪製，且需要顯示或儲存\n",
    "    num_plots = int(original) + int(modified)\n",
    "    if num_plots == 0 or not (show or save):\n",
    "        print(\"plot_foms：沒有需要顯示或儲存的圖。\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    cols = min(2, num_plots)\n",
    "    rows = int(np.ceil(num_plots / cols))\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 5, rows * 4))\n",
    "    axes = np.array(axes).flatten()  # 確保 axes 為一維陣列\n",
    "\n",
    "    def set_fig(x, y, ax, x_lim, y_lim, title, plot_method):\n",
    "        \"\"\"\n",
    "        在指定的軸 (ax) 上繪製資料並設定圖表樣式。\n",
    "\n",
    "        參數：\n",
    "            x (array-like): x 軸資料。\n",
    "            y (array-like): y 軸資料。\n",
    "            ax (matplotlib.axes.Axes): 要繪圖的子圖。\n",
    "            x_lim (tuple): x 軸界限 (min, max)。\n",
    "            y_lim (tuple): y 軸界限 (min, max)。\n",
    "            title (str): 子圖標題。\n",
    "            plot_method (str): 繪圖方法，可選 \"scatter\" 或 \"plot\"。\n",
    "        \"\"\"\n",
    "        # 根據 plot_method 繪製資料\n",
    "        if plot_method == \"scatter\":\n",
    "            ax.scatter(x, y, s=5, color=\"blue\")\n",
    "        elif plot_method == \"plot\":\n",
    "            ax.plot(x, y, color=\"blue\")\n",
    "        else:\n",
    "            print(\"無效的 plot_method 指定。\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        ax.set_xlim(x_lim)\n",
    "        ax.set_ylim(y_lim)\n",
    "        ax.set_xlabel(\"i-th Configuration\")\n",
    "        ax.set_ylabel(\"FOM\")\n",
    "        ax.set_title(title)\n",
    "\n",
    "        # 畫出分隔線（若有提供 split_idx）\n",
    "        if split_idx is not None:\n",
    "            ymin, ymax = ax.get_ylim()\n",
    "            ax.vlines(\n",
    "                x=split_idx,\n",
    "                ymin=ymin,\n",
    "                ymax=ymax,\n",
    "                colors='red',\n",
    "                linestyles='dashed',\n",
    "                label=\"Initial Random Generated Data\"\n",
    "            )\n",
    "\n",
    "        # 加入自定義圖例：顯示最小 FOM 與最佳組態資訊\n",
    "        least_fom = np.min(y)\n",
    "        best_config = np.argmin(y) + 1\n",
    "        custom_labels = [\n",
    "            f\"The Least FOM: {least_fom:.3f}\",\n",
    "            f\"{best_config}-th Configuration\"\n",
    "        ]\n",
    "        # 建立 dummy handle，分別為圖例的兩筆資訊\n",
    "        custom_handles = [\n",
    "            Line2D([], [], color='black', linestyle=''),\n",
    "            Line2D([], [], color='black', linestyle='')\n",
    "        ]\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        handles.extend(custom_handles)\n",
    "        labels.extend(custom_labels)\n",
    "        ax.legend(handles=handles, labels=labels, fontsize=10, loc='upper right')\n",
    "\n",
    "    # x 軸配置序號\n",
    "    ith_config = np.arange(1, foms.shape[0] + 1)\n",
    "    cnt = 0\n",
    "\n",
    "    if original:\n",
    "        set_fig(\n",
    "            x=ith_config,\n",
    "            y=foms,\n",
    "            ax=axes[cnt],\n",
    "            x_lim=(0, None),\n",
    "            y_lim=(-2, 0),\n",
    "            title=\"Original\",\n",
    "            plot_method=\"scatter\"\n",
    "        )\n",
    "        cnt += 1\n",
    "\n",
    "    if modified:\n",
    "        set_fig(\n",
    "            x=ith_config,\n",
    "            y=foms_modified,\n",
    "            ax=axes[cnt],\n",
    "            x_lim=(0, None),\n",
    "            y_lim=(-2, -1.4),\n",
    "            title=\"Modified\",\n",
    "            plot_method=\"plot\"\n",
    "        )\n",
    "        cnt += 1\n",
    "\n",
    "    # 移除多餘的子圖（若有）\n",
    "    for i in range(cnt, len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "\n",
    "    # 儲存圖形\n",
    "    if save:\n",
    "        fig.savefig(path, bbox_inches='tight')\n",
    "\n",
    "    # 顯示或關閉圖形\n",
    "    if show:\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88421c79-91b0-4f0d-9ea1-009adb01532c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T09:11:28.752260Z",
     "iopub.status.busy": "2025-04-23T09:11:28.751471Z",
     "iopub.status.idle": "2025-04-23T09:11:28.764326Z",
     "shell.execute_reply": "2025-04-23T09:11:28.762684Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.03161,
     "end_time": "2025-04-23T09:11:28.766861",
     "exception": false,
     "start_time": "2025-04-23T09:11:28.735251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rm_best_model():\n",
    "    folder_name = os.path.join(\".\", \"model_temp\")\n",
    "    file_name_1 = \"model_epochs_best.params\"\n",
    "    file_name_2 = \"model_epochs_best.params.trainer\"\n",
    "    path_1      = os.path.join(folder_name, file_name_1)\n",
    "    path_2      = os.path.join(folder_name, file_name_2)\n",
    "\n",
    "    if os.path.exists(path_1) and os.path.exists(path_2):\n",
    "        os.remove(path_1)\n",
    "        os.remove(path_2)\n",
    "    else:\n",
    "        print(\"沒有best model可以刪除\")\n",
    "        # sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38b7e12f-6011-40fb-bb37-44e07540265b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T09:11:28.830543Z",
     "iopub.status.busy": "2025-04-23T09:11:28.829722Z",
     "iopub.status.idle": "2025-04-23T09:11:28.878011Z",
     "shell.execute_reply": "2025-04-23T09:11:28.876348Z"
    },
    "papermill": {
     "duration": 0.099147,
     "end_time": "2025-04-23T09:11:28.879954",
     "exception": false,
     "start_time": "2025-04-23T09:11:28.780807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dynamic_FM(dynamic_retrain, var_num, K, training_set, testing_set, show=False):\n",
    "    \"\"\"\n",
    "    Purpose: Return the model with the least testing loss\n",
    "    \n",
    "    Plot\n",
    "    - x axis : epochs number\n",
    "    - y axis : loss\n",
    "\n",
    "    Parameters\n",
    "    - dynamic_retrain : \n",
    "    - var_num         : qubits數\n",
    "    - K               : factorization machine的K\n",
    "    - training_set    : [xs_train, ys_train]\n",
    "    - testing_set     : [xs_test, ys_test]\n",
    "    - show            : \n",
    "    \"\"\"\n",
    "    \n",
    "    # 預處理\n",
    "    if not testing_set[0].shape[0]:\n",
    "        print(\"dynamic_FM: testing_set筆數為0，不能用dynamic model\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    xs_train = training_set[0]\n",
    "    ys_train = training_set[1]\n",
    "    xs_test  = testing_set[0]\n",
    "    ys_test  = testing_set[1]\n",
    "    \n",
    "    # 存放losses的容器\n",
    "    training_losses = list()\n",
    "    testing_losses  = list()\n",
    "\n",
    "    # 暫存model的資料夾\n",
    "    folder_name = \"model_temp\"\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "    \n",
    "    # 設定best model的路徑\n",
    "    file_name = f\"model_epochs_best.params\"\n",
    "    path = os.path.join(folder_name, file_name)\n",
    "    \n",
    "    # 要測試的epochs（這邊規定第一筆一定要是0，這樣寫起來比較方便）\n",
    "    epochs_vec = [0,\n",
    "                  1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
    "                  10, 20, 30, 40, 50, 60, 70, 80, 90,\n",
    "                  100, 200, 300, 400, 500, 600, 700, 800, 900,\n",
    "                  1_000, 2_000, 3_000, 4_000, 5_000]#, 6_000, 7_000, 8_000, 9_000,\n",
    "                  # 10_000, 20_000, 30_000, 40_000, 50_000, 60_000, 70_000, 80_000, 90_000,\n",
    "                  # 100_000, 200_000, 300_000, 400_000, 500_000, 600_000, 700_000, 800_000, 900_000,\n",
    "                  # 1_000_000]\n",
    "    if epochs_vec[0] != 0:\n",
    "        print(\"epochs_vec的第一個元素不是0\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # 開始找這次的best model\n",
    "    for i in range(len(epochs_vec)):\n",
    "        \n",
    "        # print(f\"{epochs_vec[i]}個epochs\")\n",
    "\n",
    "        if 0 == i:    # 就是0==epochs，載入之前的best model，或是初始化model\n",
    "            if (os.path.exists(path)) and (not dynamic_retrain):\n",
    "                model = FactorizationMachine.load_model(var_num, K, path=path)\n",
    "            else:\n",
    "                model = FactorizationMachine(input_size=var_num, factorization_size=K, act=\"identity\")\n",
    "                model.init_params(initializer=mx.init.Normal())\n",
    "        else:    # 訓練model\n",
    "            epochs = epochs_vec[i] - epochs_vec[i-1]\n",
    "            model.train(xs_train, ys_train, num_epoch=epochs, learning_rate=1.0e-2)\n",
    "\n",
    "        # 存model\n",
    "        file_name = f\"model_epochs_{epochs_vec[i]}.params\"\n",
    "        path = os.path.join(folder_name, file_name)\n",
    "        model.save_model(path=path)\n",
    "\n",
    "        # 計算loss\n",
    "        training_loss = model.loss( training_set )\n",
    "        testing_loss  = model.loss( testing_set )\n",
    "        training_losses.append( training_loss )\n",
    "        testing_losses.append( testing_loss )\n",
    "\n",
    "    # 轉為numpy array方便處理\n",
    "    training_losses = np.array(training_losses, dtype=np.float64)\n",
    "    testing_losses = np.array(testing_losses, dtype=np.float64)\n",
    "    \n",
    "    # 找出最好的epochs\n",
    "    valid_epochs_vec = training_losses <= testing_losses\n",
    "    if valid_epochs_vec.any():\n",
    "        epochs_idx = np.where( testing_losses == np.min(testing_losses[valid_epochs_vec]) )[0][0]\n",
    "        best_epochs = epochs_vec[epochs_idx]\n",
    "    else:\n",
    "        print(\"所有testing set都比training set還要好，不合理 -> 應該是數據還不夠多\")\n",
    "        best_epochs = 0\n",
    "\n",
    "    # 讀取最好的epochs model\n",
    "    file_name = f\"model_epochs_{best_epochs}.params\"\n",
    "    path      = os.path.join(folder_name, file_name)\n",
    "    model     = FactorizationMachine.load_model(var_num, K, path=path)\n",
    "    \n",
    "    # 把這次的最好的epcohs model存起來（如果每次都要重頭開始重新訓練就不用存了）\n",
    "    if not dynamic_retrain:\n",
    "        path = os.path.join(folder_name, f\"model_epochs_best.params\")\n",
    "        model.save_model(path=path)\n",
    "    \n",
    "    # 畫圖\n",
    "    if show:\n",
    "        plt.plot(epochs_vec, training_losses, label=\"training_loss\")\n",
    "        plt.plot(epochs_vec, testing_losses, label=\"testing_loss\")\n",
    "        plt.xscale(\"log\")\n",
    "        plt.xlim(left=epochs_vec[1])    # 這裡就不從epochs=0開始畫了，因為log scale畫不出x=0的部分\n",
    "        plt.ylim(bottom=0)\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Loss-Epochs Curve\")\n",
    "        plt.legend(loc=\"upper left\")\n",
    "        plt.show()\n",
    "\n",
    "    # 顯示best epochs的資訊\n",
    "    print(f\"best epochs: {best_epochs}\")\n",
    "    print(f\"best epochs的training loss是: {training_losses[epochs_vec.index(best_epochs)]}\")\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9a95f08-ff3a-479b-a4e2-8f842de1bd8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T09:11:28.911365Z",
     "iopub.status.busy": "2025-04-23T09:11:28.910585Z",
     "iopub.status.idle": "2025-04-23T09:11:28.925340Z",
     "shell.execute_reply": "2025-04-23T09:11:28.923641Z"
    },
    "papermill": {
     "duration": 0.033804,
     "end_time": "2025-04-23T09:11:28.927794",
     "exception": false,
     "start_time": "2025-04-23T09:11:28.893990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_loss_iter(training_losses=None, testing_losses=None):\n",
    "    \"\"\"\n",
    "    用途：畫出每個iteration的training loss跟testing loss\n",
    "    \"\"\"\n",
    "    if (len(training_losses) != len(testing_losses)) and (len(testing_losses) != 0):\n",
    "        print(\"loss_iter出錯\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    plt.plot(training_losses, label=\"training_loss\")\n",
    "    plt.plot(testing_losses, label=\"testing_loss\")\n",
    "    plt.xlim(left=0)\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Loss-Iteration Curve\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01ae1c5a-10cd-49cd-b7b2-39e0c8385bbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T09:11:28.959125Z",
     "iopub.status.busy": "2025-04-23T09:11:28.958338Z",
     "iopub.status.idle": "2025-04-23T09:11:28.983511Z",
     "shell.execute_reply": "2025-04-23T09:11:28.981812Z"
    },
    "papermill": {
     "duration": 0.043994,
     "end_time": "2025-04-23T09:11:28.985939",
     "exception": false,
     "start_time": "2025-04-23T09:11:28.941945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_energy_fom(energy_ls, fom_ls, num_in_iter, show=False, path=\"energy_fom_ith_config_curve.png\", save=True):\n",
    "    \"\"\"\n",
    "    用途：畫出FMQA訓練過程中sample出的energy跟fom對i-th configuration的curve\n",
    "        - 橫軸：i-th configuration\n",
    "        - 縱軸：Energy/FOM\n",
    "    \n",
    "    參數\n",
    "    - num_in_group : 一個list紀錄一個iteration有幾筆new data，用來畫Energy/FOM - ith Configuration Curve的分割iteration的分割線\n",
    "    \"\"\"\n",
    "    if show or save:\n",
    "        # 定義橫軸\n",
    "        x = np.arange(1, len(energy_ls)+1)\n",
    "\n",
    "        # 畫圖\n",
    "        fig = plt.figure(figsize=(15,5))\n",
    "        ax  = fig.add_subplot()\n",
    "        ax.plot(x, energy_ls, \".\", color=\"red\", label=\"energy\")\n",
    "        ax.plot(x, fom_ls, \".\", color=\"blue\", label=\"fom\", )\n",
    "        ax.set_xlim(left=1)\n",
    "        bottom = min(np.mean(energy_ls), np.mean(fom_ls)) - 0.5\n",
    "        top    = max(np.mean(energy_ls), np.mean(fom_ls)) + 0.5\n",
    "        ax.set_ylim(bottom=bottom, top=top)\n",
    "        # ax.set_ylim(0.35, 0.45)\n",
    "        ax.set_title(\"Energy/FOM - ith Configuration Curve\", fontsize=20)\n",
    "        ax.set_xlabel(\"i-th Configuration\", fontsize=16)\n",
    "        ax.set_ylabel(\"Energy / FOM\", fontsize=16)\n",
    "        ax.legend()\n",
    "        \n",
    "        # 加上分割線（同一塊的energy/fom都是在同個iteration新增的）\n",
    "        for x in num_in_iter:\n",
    "            ax.axvline(x=x+0.5, color='gray', linestyle='--', linewidth=1)\n",
    "        \n",
    "        # 存圖\n",
    "        if save:\n",
    "            fig.savefig(path, bbox_inches='tight')\n",
    "    \n",
    "        # 顯示\n",
    "        if show:\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "    \n",
    "    else:\n",
    "        print(f\"\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70322061-2c30-488f-98a0-aaa85cfa56f4",
   "metadata": {
    "papermill": {
     "duration": 0.012864,
     "end_time": "2025-04-23T09:11:29.012041",
     "exception": false,
     "start_time": "2025-04-23T09:11:28.999177",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# FMQA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daa6395-939d-4460-b309-69bb7404c81f",
   "metadata": {
    "papermill": {
     "duration": 0.011115,
     "end_time": "2025-04-23T09:11:29.035664",
     "exception": false,
     "start_time": "2025-04-23T09:11:29.024549",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Generating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "130d492c-8da6-4b54-93c3-c327b1270f39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T09:11:29.060208Z",
     "iopub.status.busy": "2025-04-23T09:11:29.059419Z",
     "iopub.status.idle": "2025-04-23T09:11:29.070126Z",
     "shell.execute_reply": "2025-04-23T09:11:29.068469Z"
    },
    "papermill": {
     "duration": 0.026013,
     "end_time": "2025-04-23T09:11:29.072392",
     "exception": false,
     "start_time": "2025-04-23T09:11:29.046379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 生成數據 - 使用read_file\n",
    "\n",
    "# # 定義路徑\n",
    "# folder_name = os.path.join(\"figure_of_merit\", target[0])\n",
    "# file_name   = f\"{rings}_{'_'.join(map(str, target))}_ground_truth.csv\"\n",
    "# path = os.path.join(folder_name, file_name)\n",
    "\n",
    "# # 讀檔\n",
    "# configs, foms = read_file(\n",
    "#                     method = init_dataset_method,\n",
    "#                     n      = init_dataset_size,\n",
    "#                     k      = init_dataset_top_k_percent,\n",
    "#                     thresh = init_dataset_fom_thresh,\n",
    "#                     repeat = init_dataset_repeat,\n",
    "#                     path   = path\n",
    "#                 )\n",
    "# if (configs.shape[0] != init_dataset_size) or (foms.shape[0] != init_dataset_size):\n",
    "#     print(f\"read_file的輸出筆數有錯\")\n",
    "#     print(f\"輸出筆數：{configs.shape}\")\n",
    "#     print(f\"應該要輸出的筆數：{init_dataset_size}\")\n",
    "#     sys.exit(1)\n",
    "\n",
    "# # 分為training set跟testing set\n",
    "# split_idx = init_trainset_size\n",
    "# configs_train, configs_test = configs[:split_idx], configs[split_idx:]\n",
    "# foms_train, foms_test       = foms[:split_idx], foms[split_idx:]\n",
    "# training_set = [configs_train, foms_train]\n",
    "# testing_set  = [configs_test, foms_test]\n",
    "# if (configs_train.shape[0] != init_trainset_size) or (configs_test.shape[0] != init_testset_size) or \\\n",
    "#    (foms_train.shape[0] != init_trainset_size) or (foms_test.shape[0] != init_testset_size):\n",
    "#     print(f\"training set, testing set的筆數有錯\")\n",
    "#     print(f\"正確的initial training set size: {init_trainset_size}\")\n",
    "#     print(f\"實際的initial training set size: {configs_train.shape[0]}\")\n",
    "#     sys.exit(1)\n",
    "\n",
    "# # 顯示最小FOM\n",
    "# if training_set[0].shape[0]:\n",
    "#     print(f\"training set的最小FOM: {np.min(training_set[1])}\")\n",
    "# if testing_set[0].shape[0]:\n",
    "#     print(f\"testing set的最小FOM:  {np.min(testing_set[1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5aaf774-ea1a-4a47-8faa-6e089c3ffe32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T09:11:29.097040Z",
     "iopub.status.busy": "2025-04-23T09:11:29.096249Z",
     "iopub.status.idle": "2025-04-23T09:11:44.722037Z",
     "shell.execute_reply": "2025-04-23T09:11:44.720813Z"
    },
    "papermill": {
     "duration": 15.643363,
     "end_time": "2025-04-23T09:11:44.726454",
     "exception": false,
     "start_time": "2025-04-23T09:11:29.083091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest FOM in the training set: -1.6362871841655446\n"
     ]
    }
   ],
   "source": [
    "# 生成的部分OK\n",
    "# 但是讀取的部分之後要改成用read_file函數\n",
    "\n",
    "# Define path -> \"./figure_of_merit/{target[0]}/{rings}_{target[...]}_init_{init_dataset_size}.csv\"\n",
    "# folder_name = os.path.join(\"figure_of_merit\", target[0])\n",
    "# file_name   = f\"{rings}_{'_'.join(map(str, target))}_init_{init_dataset_size}.csv\"\n",
    "# path = os.path.join(folder_name, file_name)\n",
    "\n",
    "# # Generating data\n",
    "# if os.path.exists(path):\n",
    "#     df = pd.read_csv(path)\n",
    "#     configs = df.iloc[:, :-1].to_numpy(dtype=np.int8)\n",
    "#     foms    = df.iloc[:, -1].to_numpy(dtype=np.float64)\n",
    "# else:\n",
    "#     configs = generate_unique_binary_array(init_dataset_size, rings)\n",
    "#     foms    = foms_calc(configs, resolution, multiple, target)\n",
    "#     # Save to a DataFrame\n",
    "#     header_rings = [f\"ring{i+1}\" for i in range(rings)]\n",
    "#     df = pd.DataFrame(configs, columns=header_rings, dtype=np.int8)\n",
    "#     df[\"FOM\"] = foms\n",
    "#     # Save to a CSV file\n",
    "#     os.makedirs(folder_name, exist_ok=True)\n",
    "#     df.to_csv(path, mode='w', header=True, index=False)\n",
    "#configs = generate_unique_binary_array(init_dataset_size, rings)\n",
    "configs =np.random.randint(2, size=(init_dataset_size, rings), dtype=np.int8)\n",
    "foms    = foms_calc(configs, resolution, multiple, target)\n",
    "# Split to the training set and the testing set\n",
    "split_idx = init_trainset_size\n",
    "configs_train, configs_test = configs[:split_idx], configs[split_idx:]\n",
    "foms_train, foms_test       = foms[:split_idx], foms[split_idx:]\n",
    "training_set = [configs_train, foms_train]\n",
    "testing_set  = [configs_test, foms_test]\n",
    "\n",
    "# Print the smallest FOM\n",
    "if training_set[0].shape[0]:\n",
    "    print(f\"Smallest FOM in the training set: {np.min(training_set[1])}\")\n",
    "if testing_set[0].shape[0]:\n",
    "    print(f\"Smallest FOM in the testing set:  {np.min(testing_set[1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a73a36-c2a7-42d4-ac55-ab59d23d222e",
   "metadata": {
    "papermill": {
     "duration": 0.026211,
     "end_time": "2025-04-23T09:11:44.790977",
     "exception": false,
     "start_time": "2025-04-23T09:11:44.764766",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Initial Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94d0174f-d561-42bb-bd42-da5f9850be93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T09:11:44.824784Z",
     "iopub.status.busy": "2025-04-23T09:11:44.824504Z",
     "iopub.status.idle": "2025-04-23T09:11:44.829467Z",
     "shell.execute_reply": "2025-04-23T09:11:44.828446Z"
    },
    "papermill": {
     "duration": 0.022869,
     "end_time": "2025-04-23T09:11:44.831654",
     "exception": false,
     "start_time": "2025-04-23T09:11:44.808785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 看看FOM的分布\n",
    "# bin_edges = np.arange(0, max(foms) + 0.1, 0.1)\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(foms, bins=bin_edges, edgecolor='black', alpha=0.7)\n",
    "# plt.xlim(0)\n",
    "# plt.grid()\n",
    "# plt.title(\"Initial FOMs Distribution\")\n",
    "# plt.xlabel(\"FOM\")\n",
    "# plt.ylabel(\"times\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424d1c70-d109-4323-b75f-ce2d03234677",
   "metadata": {
    "papermill": {
     "duration": 0.012219,
     "end_time": "2025-04-23T09:11:44.856013",
     "exception": false,
     "start_time": "2025-04-23T09:11:44.843794",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed55a1e",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6341cc21-bf87-4d4a-a8f3-4392a54fc671",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T09:11:44.883309Z",
     "iopub.status.busy": "2025-04-23T09:11:44.882708Z",
     "iopub.status.idle": "2025-04-23T09:14:20.562444Z",
     "shell.execute_reply": "2025-04-23T09:14:20.560676Z"
    },
    "papermill": {
     "duration": 155.702591,
     "end_time": "2025-04-23T09:14:20.571037",
     "exception": true,
     "start_time": "2025-04-23T09:11:44.868446",
     "status": "failed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1次iteration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練FM的時間: 1.2326877117156982 秒\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "畫Q Matrix的時間：0.2309739589691162 秒\n",
      "QA sample的時間: 0.060459136962890625 秒\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "計算new data的時間: 9.466105699539185 秒\n",
      "原先設定的新增筆數: 200\n",
      "最終實際新增的筆數: 200（會因為簡併態、不允許重複數據而造成跟原先設定的筆數不同）\n",
      "這個iter最小的foms_train: -1.5045826121293941\n",
      "**************************************************\n",
      "第2次iteration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練FM的時間: 1.268193244934082 秒\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "畫Q Matrix的時間：0.22542285919189453 秒\n",
      "QA sample的時間: 0.06033611297607422 秒\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "計算new data的時間: 8.78257131576538 秒\n",
      "原先設定的新增筆數: 200\n",
      "最終實際新增的筆數: 200（會因為簡併態、不允許重複數據而造成跟原先設定的筆數不同）\n",
      "這個iter最小的foms_train: -1.6965843065487183\n",
      "**************************************************\n",
      "第3次iteration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練FM的時間: 1.1620604991912842 秒\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "畫Q Matrix的時間：0.2034590244293213 秒\n",
      "QA sample的時間: 0.060346364974975586 秒\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "計算new data的時間: 8.77920913696289 秒\n",
      "原先設定的新增筆數: 200\n",
      "最終實際新增的筆數: 200（會因為簡併態、不允許重複數據而造成跟原先設定的筆數不同）\n",
      "這個iter最小的foms_train: -1.7094026625423395\n",
      "**************************************************\n",
      "第4次iteration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練FM的時間: 1.1935358047485352 秒\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "畫Q Matrix的時間：0.16422653198242188 秒\n",
      "QA sample的時間: 0.049231767654418945 秒\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "計算new data的時間: 8.525134325027466 秒\n",
      "原先設定的新增筆數: 200\n",
      "最終實際新增的筆數: 200（會因為簡併態、不允許重複數據而造成跟原先設定的筆數不同）\n",
      "這個iter最小的foms_train: -1.70508667716983\n",
      "**************************************************\n",
      "第5次iteration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練FM的時間: 1.2461519241333008 秒\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "畫Q Matrix的時間：0.15995359420776367 秒\n",
      "QA sample的時間: 0.04991412162780762 秒\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "計算new data的時間: 8.403764247894287 秒\n",
      "原先設定的新增筆數: 200\n",
      "最終實際新增的筆數: 200（會因為簡併態、不允許重複數據而造成跟原先設定的筆數不同）\n",
      "這個iter最小的foms_train: -1.6241263718681869\n",
      "**************************************************\n",
      "第6次iteration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練FM的時間: 1.2061688899993896 秒\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "畫Q Matrix的時間：0.1611166000366211 秒\n",
      "QA sample的時間: 0.05635547637939453 秒\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "計算new data的時間: 8.824822902679443 秒\n",
      "原先設定的新增筆數: 200\n",
      "最終實際新增的筆數: 200（會因為簡併態、不允許重複數據而造成跟原先設定的筆數不同）\n",
      "這個iter最小的foms_train: -1.6549456251291863\n",
      "**************************************************\n",
      "第7次iteration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練FM的時間: 1.2119860649108887 秒\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "畫Q Matrix的時間：0.17335152626037598 秒\n",
      "QA sample的時間: 0.04972076416015625 秒\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "計算new data的時間: 7.916669607162476 秒\n",
      "原先設定的新增筆數: 200\n",
      "最終實際新增的筆數: 200（會因為簡併態、不允許重複數據而造成跟原先設定的筆數不同）\n",
      "這個iter最小的foms_train: -1.7273421918800629\n",
      "**************************************************\n",
      "第8次iteration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練FM的時間: 1.3648109436035156 秒\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "畫Q Matrix的時間：0.19009947776794434 秒\n",
      "QA sample的時間: 0.060198068618774414 秒\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "計算new data的時間: 8.33100414276123 秒\n",
      "原先設定的新增筆數: 200\n",
      "最終實際新增的筆數: 200（會因為簡併態、不允許重複數據而造成跟原先設定的筆數不同）\n",
      "這個iter最小的foms_train: -1.5902181068990557\n",
      "**************************************************\n",
      "第9次iteration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練FM的時間: 1.1899051666259766 秒\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "畫Q Matrix的時間：0.18690276145935059 秒\n",
      "QA sample的時間: 0.060122013092041016 秒\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "計算new data的時間: 8.735816955566406 秒\n",
      "原先設定的新增筆數: 200\n",
      "最終實際新增的筆數: 200（會因為簡併態、不允許重複數據而造成跟原先設定的筆數不同）\n",
      "這個iter最小的foms_train: -1.6974189778410311\n",
      "**************************************************\n",
      "第10次iteration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練FM的時間: 1.182832956314087 秒\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "畫Q Matrix的時間：0.18616437911987305 秒\n",
      "QA sample的時間: 0.057733774185180664 秒\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "計算new data的時間: 8.93638014793396 秒\n",
      "原先設定的新增筆數: 200\n",
      "最終實際新增的筆數: 200（會因為簡併態、不允許重複數據而造成跟原先設定的筆數不同）\n",
      "這個iter最小的foms_train: -1.6473819212988545\n",
      "**************************************************\n",
      "第11次iteration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練FM的時間: 1.2908987998962402 秒\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "畫Q Matrix的時間：0.15638971328735352 秒\n",
      "QA sample的時間: 0.048615455627441406 秒\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "計算new data的時間: 7.8061299324035645 秒\n",
      "原先設定的新增筆數: 200\n",
      "最終實際新增的筆數: 200（會因為簡併態、不允許重複數據而造成跟原先設定的筆數不同）\n",
      "這個iter最小的foms_train: -1.6274465506370084\n",
      "**************************************************\n",
      "第12次iteration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練FM的時間: 1.3609094619750977 秒\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "畫Q Matrix的時間：0.1832563877105713 秒\n",
      "QA sample的時間: 0.0575413703918457 秒\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "計算new data的時間: 7.930267095565796 秒\n",
      "原先設定的新增筆數: 200\n",
      "最終實際新增的筆數: 200（會因為簡併態、不允許重複數據而造成跟原先設定的筆數不同）\n",
      "這個iter最小的foms_train: -1.7054103093506943\n",
      "**************************************************\n",
      "第13次iteration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練FM的時間: 1.203382968902588 秒\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "畫Q Matrix的時間：0.19044113159179688 秒\n",
      "QA sample的時間: 0.060616254806518555 秒\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteDisconnected\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda/envs/ocean/lib/python3.8/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/ocean/lib/python3.8/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda/envs/ocean/lib/python3.8/site-packages/urllib3/connection.py:464\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 464\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda/envs/ocean/lib/python3.8/http/client.py:1348\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1349\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda/envs/ocean/lib/python3.8/http/client.py:316\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n",
      "File \u001b[0;32m~/miniconda/envs/ocean/lib/python3.8/http/client.py:285\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line:\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;66;03m# Presumably, the server closed the connection before\u001b[39;00m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;66;03m# sending a valid response.\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RemoteDisconnected(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemote end closed connection without\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m response\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mRemoteDisconnected\u001b[0m: Remote end closed connection without response",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda/envs/ocean/lib/python3.8/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda/envs/ocean/lib/python3.8/site-packages/urllib3/connectionpool.py:843\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    841\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 843\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    846\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/miniconda/envs/ocean/lib/python3.8/site-packages/urllib3/util/retry.py:474\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_method_retryable(method):\n\u001b[0;32m--> 474\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda/envs/ocean/lib/python3.8/site-packages/urllib3/util/util.py:38\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "File \u001b[0;32m~/miniconda/envs/ocean/lib/python3.8/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/ocean/lib/python3.8/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda/envs/ocean/lib/python3.8/site-packages/urllib3/connection.py:464\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 464\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda/envs/ocean/lib/python3.8/http/client.py:1348\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1349\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda/envs/ocean/lib/python3.8/http/client.py:316\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n",
      "File \u001b[0;32m~/miniconda/envs/ocean/lib/python3.8/http/client.py:285\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line:\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;66;03m# Presumably, the server closed the connection before\u001b[39;00m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;66;03m# sending a valid response.\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RemoteDisconnected(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemote end closed connection without\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m response\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mProtocolError\u001b[0m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 100\u001b[0m\n\u001b[1;32m     98\u001b[0m     new_foms     \u001b[38;5;241m=\u001b[39m foms_temp[smallest_foms_indices]\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 100\u001b[0m     new_configs, new_energies, new_foms \u001b[38;5;241m=\u001b[39m \u001b[43madd_new_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43madd_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampleset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_adds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mresolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolution\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultiple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmultiple\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m new_data_time_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m計算new data的時間: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_data_time_end\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mnew_data_time_start\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 秒\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[11], line 32\u001b[0m, in \u001b[0;36madd_new_data\u001b[0;34m(add_method, sampleset, num_adds, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Implementation of each adding method\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m add_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_fom\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 32\u001b[0m     foms_sampled \u001b[38;5;241m=\u001b[39m foms_calc(\u001b[43msampleset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecord\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample\u001b[39m\u001b[38;5;124m\"\u001b[39m], resolution, multiple, target)\n\u001b[1;32m     33\u001b[0m     adds_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(foms_sampled)[:num_adds]\n\u001b[1;32m     34\u001b[0m     new_configs  \u001b[38;5;241m=\u001b[39m sampleset\u001b[38;5;241m.\u001b[39mrecord[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample\u001b[39m\u001b[38;5;124m\"\u001b[39m][adds_indices]\n",
      "File \u001b[0;32m~/miniconda/envs/ocean/lib/python3.8/site-packages/dimod/sampleset.py:1121\u001b[0m, in \u001b[0;36mSampleSet.record\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecord\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\":obj:`numpy.recarray` containing the samples, energies, number of occurences, and other sample data.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \n\u001b[1;32m   1109\u001b[0m \u001b[38;5;124;03m    Examples:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \n\u001b[1;32m   1120\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_record\n",
      "File \u001b[0;32m~/miniconda/envs/ocean/lib/python3.8/site-packages/dimod/sampleset.py:1485\u001b[0m, in \u001b[0;36mSampleSet.resolve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1483\u001b[0m \u001b[38;5;66;03m# if it doesn't have the attribute then it is already resolved\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_future\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m-> 1485\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_result_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_future\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(samples\u001b[38;5;241m.\u001b[39mrecord, samples\u001b[38;5;241m.\u001b[39mvariables, samples\u001b[38;5;241m.\u001b[39minfo, samples\u001b[38;5;241m.\u001b[39mvartype)\n\u001b[1;32m   1487\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_future\n",
      "File \u001b[0;32m~/miniconda/envs/ocean/lib/python3.8/site-packages/dwave/system/composites/embedding.py:284\u001b[0m, in \u001b[0;36mEmbeddingComposite.sample.<locals>.async_unembed\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21masync_unembed\u001b[39m(response):\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;66;03m# unembed the sampleset aysnchronously.\u001b[39;00m\n\u001b[1;32m    282\u001b[0m     warninghandler\u001b[38;5;241m.\u001b[39mchain_break(response, embedding)\n\u001b[0;32m--> 284\u001b[0m     sampleset \u001b[38;5;241m=\u001b[39m \u001b[43munembed_sampleset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_bqm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbqm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mchain_break_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchain_break_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mchain_break_fraction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchain_break_fraction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mreturn_embedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_embedding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_embedding:\n\u001b[1;32m    290\u001b[0m         sampleset\u001b[38;5;241m.\u001b[39minfo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding_context\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m    291\u001b[0m             embedding_parameters\u001b[38;5;241m=\u001b[39membedding_parameters,\n\u001b[1;32m    292\u001b[0m             chain_strength\u001b[38;5;241m=\u001b[39membedding\u001b[38;5;241m.\u001b[39mchain_strength)\n",
      "File \u001b[0;32m~/miniconda/envs/ocean/lib/python3.8/site-packages/dwave/embedding/transforms.py:606\u001b[0m, in \u001b[0;36munembed_sampleset\u001b[0;34m(target_sampleset, embedding, source_bqm, chain_break_method, chain_break_fraction, return_embedding)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgiven bqm does not match the embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 606\u001b[0m record \u001b[38;5;241m=\u001b[39m \u001b[43mtarget_sampleset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecord\u001b[49m\n\u001b[1;32m    608\u001b[0m unembedded, idxs \u001b[38;5;241m=\u001b[39m chain_break_method(target_sampleset, chains)\n\u001b[1;32m    610\u001b[0m reserved \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124menergy\u001b[39m\u001b[38;5;124m'\u001b[39m}\n",
      "File \u001b[0;32m~/miniconda/envs/ocean/lib/python3.8/site-packages/dimod/sampleset.py:1121\u001b[0m, in \u001b[0;36mSampleSet.record\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecord\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\":obj:`numpy.recarray` containing the samples, energies, number of occurences, and other sample data.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \n\u001b[1;32m   1109\u001b[0m \u001b[38;5;124;03m    Examples:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \n\u001b[1;32m   1120\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_record\n",
      "File \u001b[0;32m~/miniconda/envs/ocean/lib/python3.8/site-packages/dimod/sampleset.py:1485\u001b[0m, in \u001b[0;36mSampleSet.resolve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1483\u001b[0m \u001b[38;5;66;03m# if it doesn't have the attribute then it is already resolved\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_future\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m-> 1485\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_result_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_future\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(samples\u001b[38;5;241m.\u001b[39mrecord, samples\u001b[38;5;241m.\u001b[39mvariables, samples\u001b[38;5;241m.\u001b[39minfo, samples\u001b[38;5;241m.\u001b[39mvartype)\n\u001b[1;32m   1487\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_future\n",
      "File \u001b[0;32m~/miniconda/envs/ocean/lib/python3.8/site-packages/dwave/system/samplers/dwave_sampler.py:439\u001b[0m, in \u001b[0;36mDWaveSampler.sample.<locals>._hook\u001b[0;34m(computation)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sampleset\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomputation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProblemUploadError, RequestTimeout, PollingTimeout) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfailover:\n",
      "File \u001b[0;32m~/miniconda/envs/ocean/lib/python3.8/site-packages/dwave/system/samplers/dwave_sampler.py:429\u001b[0m, in \u001b[0;36mDWaveSampler.sample.<locals>._hook.<locals>.resolve\u001b[0;34m(computation)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresolve\u001b[39m(computation):\n\u001b[1;32m    428\u001b[0m     sampleset \u001b[38;5;241m=\u001b[39m computation\u001b[38;5;241m.\u001b[39msampleset\n\u001b[0;32m--> 429\u001b[0m     \u001b[43msampleset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m warninghandler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    432\u001b[0m         warninghandler\u001b[38;5;241m.\u001b[39mtoo_few_samples(sampleset)\n",
      "File \u001b[0;32m~/miniconda/envs/ocean/lib/python3.8/site-packages/dimod/sampleset.py:1485\u001b[0m, in \u001b[0;36mSampleSet.resolve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1483\u001b[0m \u001b[38;5;66;03m# if it doesn't have the attribute then it is already resolved\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_future\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m-> 1485\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_result_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_future\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(samples\u001b[38;5;241m.\u001b[39mrecord, samples\u001b[38;5;241m.\u001b[39mvariables, samples\u001b[38;5;241m.\u001b[39minfo, samples\u001b[38;5;241m.\u001b[39mvartype)\n\u001b[1;32m   1487\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_future\n",
      "File \u001b[0;32m~/miniconda/envs/ocean/lib/python3.8/site-packages/dwave/cloud/computation.py:823\u001b[0m, in \u001b[0;36mFuture.sampleset.<locals>.<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt construct SampleSet without dimod. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    820\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-install the library with \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbqm\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m support.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampleset \u001b[38;5;241m=\u001b[39m sampleset \u001b[38;5;241m=\u001b[39m dimod\u001b[38;5;241m.\u001b[39mSampleSet\u001b[38;5;241m.\u001b[39mfrom_future(\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m f: \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_sampleset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    825\u001b[0m \u001b[38;5;66;03m# propagate id to sampleset as well\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;66;03m# note: this requires dimod>=0.8.21 (before that version SampleSet\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;66;03m# had slots set which prevented dynamic addition of attributes).\u001b[39;00m\n\u001b[1;32m    828\u001b[0m sampleset\u001b[38;5;241m.\u001b[39mwait_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait_id\n",
      "File \u001b[0;32m~/miniconda/envs/ocean/lib/python3.8/site-packages/dwave/cloud/computation.py:755\u001b[0m, in \u001b[0;36mFuture.wait_sampleset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Blocking sampleset getter.\"\"\"\u001b[39;00m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;66;03m# blocking result get\u001b[39;00m\n\u001b[0;32m--> 755\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;66;03m# common problem info: id/label\u001b[39;00m\n\u001b[1;32m    758\u001b[0m problem_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(problem_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid)\n",
      "File \u001b[0;32m~/miniconda/envs/ocean/lib/python3.8/site-packages/dwave/cloud/computation.py:893\u001b[0m, in \u001b[0;36mFuture._load_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[38;5;66;03m# Check for other error conditions\u001b[39;00m\n\u001b[1;32m    892\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 893\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    895\u001b[0m \u001b[38;5;66;03m# If someone else took care of this while we were waiting\u001b[39;00m\n\u001b[1;32m    896\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda/envs/ocean/lib/python3.8/site-packages/dwave/cloud/client/base.py:1258\u001b[0m, in \u001b[0;36mClient._do_submit_problems\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1256\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(msg\u001b[38;5;241m.\u001b[39mbody\u001b[38;5;241m.\u001b[39mresult() \u001b[38;5;28;01mfor\u001b[39;00m msg \u001b[38;5;129;01min\u001b[39;00m ready_problems) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1257\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSize of POST body = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(body))\n\u001b[0;32m-> 1258\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[43mClient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sapi_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mproblems/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1259\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished submitting \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m problems\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(ready_problems))\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniconda/envs/ocean/lib/python3.8/site-packages/dwave/cloud/client/base.py:1676\u001b[0m, in \u001b[0;36mClient._sapi_request\u001b[0;34m(meth, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1674\u001b[0m \u001b[38;5;66;03m# execute request\u001b[39;00m\n\u001b[1;32m   1675\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1676\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m   1678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_caused_by(exc, (requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mTimeout,\n\u001b[1;32m   1679\u001b[0m                           urllib3\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mTimeoutError)):\n",
      "File \u001b[0;32m~/miniconda/envs/ocean/lib/python3.8/site-packages/requests/sessions.py:637\u001b[0m, in \u001b[0;36mSession.post\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    627\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \n\u001b[1;32m    629\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/ocean/lib/python3.8/site-packages/dwave/cloud/utils.py:345\u001b[0m, in \u001b[0;36mBaseUrlSession.request\u001b[0;34m(self, method, url, *args, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send the request after generating the complete URL.\"\"\"\u001b[39;00m\n\u001b[1;32m    344\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_url(url)\n\u001b[0;32m--> 345\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/ocean/lib/python3.8/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniconda/envs/ocean/lib/python3.8/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/miniconda/envs/ocean/lib/python3.8/site-packages/dwave/cloud/utils.py:318\u001b[0m, in \u001b[0;36mPretimedHTTPAdapter.send\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;66;03m# can't use setdefault because caller always sets timeout kwarg\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout\n\u001b[0;32m--> 318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/ocean/lib/python3.8/site-packages/requests/adapters.py:682\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[1;32m    668\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    669\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    678\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    679\u001b[0m     )\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MaxRetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ConnectTimeoutError):\n\u001b[1;32m    686\u001b[0m         \u001b[38;5;66;03m# TODO: Remove this in 3.0.0: see #2811\u001b[39;00m\n",
      "\u001b[0;31mConnectionError\u001b[0m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))"
     ]
    }
   ],
   "source": [
    "# 初始化FM model（沒用dynamic_FM才需要）\n",
    "if not use_dynamic_FM:\n",
    "    model = FactorizationMachine(input_size=rings, factorization_size=K, act=\"identity\")\n",
    "    model.init_params(initializer=mx.init.Normal())\n",
    "    # model.init_params(initializer=mx.init.Xavier())    # 之後dynamic_FM也試試這個\n",
    "model.bqm()\n",
    "\n",
    "# 刪除上次的best model（用dynamic_FM才需要）\n",
    "if use_dynamic_FM:\n",
    "    rm_best_model()\n",
    "\n",
    "# 初始化存放FM loss的容器\n",
    "training_losses = []\n",
    "testing_losses  = []\n",
    "\n",
    "# 初始化存放sampling energy, fom的容器（only for training set）\n",
    "energy_ls = []\n",
    "fom_ls    = []\n",
    "num_in_iter = []    # 用來記錄每個iteration增加幾筆new data\n",
    "\n",
    "# 建立存放Q matrix的資料夾 & 刪除之前的暫存檔\n",
    "folder_name = \"Q_matrix_temp\"\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "for file_path in glob.glob(os.path.join(folder_name, \"*\")):\n",
    "    if os.path.isfile(file_path):\n",
    "        os.remove(file_path)\n",
    "\n",
    "# 開始跑整個FMQA的流程\n",
    "i = 0\n",
    "start_time = time.time()    # 計時開始（計整個訓練要跑的時間）\n",
    "while i < iteration:\n",
    "    \n",
    "    # 顯示目前訓練的是第幾次iter (從1開始)\n",
    "    print(f\"第{i+1}次iteration\")\n",
    "\n",
    "    # Factorization Machine\n",
    "    fm_training_time_start = time.time()    # FM計時開始\n",
    "    if use_dynamic_FM:\n",
    "        model = dynamic_FM(dynamic_retrain, rings, K, training_set, testing_set, show=True)\n",
    "    else:\n",
    "        model.train(configs_train, foms_train, num_epoch=num_epoch)\n",
    "    fm_training_time_end   = time.time()    # FM計時結束\n",
    "    print(f\"訓練FM的時間: {fm_training_time_end - fm_training_time_start} 秒\")    # 顯示FM的訓練時間\n",
    "\n",
    "    training_losses.append( model.loss(training_set) )\n",
    "    if testing_set[0].shape[0]:\n",
    "        testing_losses.append( model.loss(testing_set) )\n",
    "\n",
    "    # Q Matrix (從1開始)\n",
    "    Q_matrix_start_time = time.time()\n",
    "    path_fig  = os.path.join(folder_name, f\"Q_matrix_{len(training_losses)}.png\")    # 因為i可能被reset，所以這裡用training_losses有幾個元素來判斷實際是第幾次迴圈（從1開始）才正確\n",
    "    path_data = os.path.join(folder_name, f\"Q_matrix_{len(training_losses)}.npy\")\n",
    "    model.plot_Q_matrix(show_fig=False, path_fig=path_fig, save_fig=True, path_data=path_data, save_data=True)\n",
    "    Q_matrix_end_time = time.time()\n",
    "    print(f\"畫Q Matrix的時間：{Q_matrix_end_time - Q_matrix_start_time} 秒\")\n",
    "\n",
    "    # 動態num_reads, num_adds\n",
    "    if dynamic_sampling:\n",
    "        dataset_size = len(training_set[0]) + len(testing_set[0])\n",
    "        num_adds, num_reads = num_reads_adds_generator(dataset_size, num_adds_ratio, num_reads_ratio, num_adds_limit)\n",
    "        print(f\"num_adds = {num_adds}, num_reads = {num_reads}\")\n",
    "    \n",
    "    # QUBO Sampling\n",
    "    sampling_time_start = time.time()    # sampling計時開始\n",
    "    if sampler_type == \"Exact\":\n",
    "        sampleset = sampler.sample(model.bqm())\n",
    "    elif sampler_type == \"SA\":\n",
    "        sampleset = sampler.sample(model.bqm(), num_reads=num_reads)\n",
    "    elif sampler_type == \"QA\":\n",
    "        sampleset = sampler.sample(\n",
    "                                model.bqm(),\n",
    "                                num_reads=num_reads,\n",
    "                                annealing_time=annealing_time,\n",
    "                                label=task_name\n",
    "                            )\n",
    "    else:\n",
    "        print(\"沒有這個sampler\")\n",
    "        sys.exit(1)\n",
    "    sampling_time_end = time.time()    # sampling計時結束\n",
    "    print(f\"{sampler_type} sample的時間: {sampling_time_end - sampling_time_start} 秒\")    # 顯示sampling時間\n",
    "    # print(f\"Sampler得出的energy: \", sampleset.record[\"energy\"])    # num_reads多的時候不要顯示\n",
    "    # print(f\"Sample出的最低能量：{np.min(sampleset.record['energy'])}\")\n",
    "    \n",
    "    new_data_time_start = time.time()\n",
    "    if sampler_type == \"Exact\":\n",
    "        # 因為exact solver比較不一樣，所以這裡自己實現new_configs, new_energies, new_foms -> 避免使用到add_new_data, sort_new_data函數\n",
    "        # 這裡實現的是: min_fom\n",
    "        # 方法：先挑出num_reads筆最小energies的組態（不重複），再從其中取出num_adds筆最小FOMs的組態\n",
    "        configs_temp = sampleset.record[\"sample\"]\n",
    "        energies_temp = sampleset.record[\"energy\"]\n",
    "        smallest_energies_indices = np.argsort(energies_temp)[:num_reads]\n",
    "        configs_temp = configs_temp[smallest_energies_indices]\n",
    "        energies_temp = energies_temp[smallest_energies_indices]\n",
    "        foms_temp = foms_calc(configs_temp, resolution, multiple, target)\n",
    "        smallest_foms_indices = np.argsort(foms_temp)[:num_adds]\n",
    "        new_configs  = configs_temp[smallest_foms_indices]\n",
    "        new_energies = energies_temp[smallest_foms_indices]\n",
    "        new_foms     = foms_temp[smallest_foms_indices]\n",
    "    else:\n",
    "        new_configs, new_energies, new_foms = add_new_data(add_method, sampleset, num_adds,\n",
    "                                                           resolution=resolution, multiple=multiple, target=target)\n",
    "    new_data_time_end = time.time()\n",
    "    print(f\"計算new data的時間: {new_data_time_end - new_data_time_start} 秒\")\n",
    "\n",
    "    # 不允許出現重複的數據(generated by Grok, haven't been tested much yet)\n",
    "    # 待修正1：這邊僅先考慮只有training set的情況\n",
    "    # 待修正2：這裡是在計算完foms才刪除的，如果要效率比較好應該在計算foms前就把重複的configs先刪除，但是因為add_new_data是直接傳sampleset造成實現上有點困難\n",
    "    # Step 1: Remove duplicates within new_configs itself\n",
    "    # Use unique with return_index to get indices of unique rows\n",
    "    unique_indices = np.unique(new_configs, axis=0, return_index=True)[1]\n",
    "    # Sort indices to maintain original order if needed\n",
    "    unique_indices = np.sort(unique_indices)\n",
    "    # Update all three arrays to remove self-duplicates\n",
    "    new_configs = new_configs[unique_indices]\n",
    "    new_energies = new_energies[unique_indices]\n",
    "    new_foms = new_foms[unique_indices]\n",
    "    # Step 2: Remove rows in new_configs that match any row in configs_train\n",
    "    # Create a boolean mask for rows in new_configs that are not in configs_train\n",
    "    mask = ~np.any(np.all(new_configs[:, None] == configs_train[None, :], axis=-1), axis=1)\n",
    "    # Apply mask to all three arrays\n",
    "    new_configs = new_configs[mask]\n",
    "    new_energies = new_energies[mask]\n",
    "    new_foms = new_foms[mask]\n",
    "\n",
    "    # 顯示原先設定的新增筆數 & 實際新增的筆數\n",
    "    print(f\"原先設定的新增筆數: {num_adds}\")\n",
    "    print(f\"最終實際新增的筆數: {len(new_configs)}（會因為簡併態、不允許重複數據而造成跟原先設定的筆數不同）\")\n",
    "    \n",
    "    # 決定new data要怎麼新增到training, testing set，並且進行排序\n",
    "    new_data_split_idx = math.ceil( len(new_configs) * new_data_split_ratio )    # 放到新training set的下標+1\n",
    "    new_configs_train, new_configs_test   = new_configs[:new_data_split_idx], new_configs[new_data_split_idx:]\n",
    "    new_energies_train, new_energies_test = new_energies[:new_data_split_idx], new_energies[new_data_split_idx:]\n",
    "    new_foms_train, new_foms_test         = new_foms[:new_data_split_idx], new_foms[new_data_split_idx:]\n",
    "    if \"min_fom\" == add_method:\n",
    "        sort_method = \"fom_ascent\"\n",
    "    elif \"min_energy\" == add_method:\n",
    "        sort_method = \"energy_ascent\"\n",
    "    else:\n",
    "        sort_method = None\n",
    "    if sampler_type != \"Exact\":\n",
    "        new_configs_train, new_energies_train, new_foms_train = sort_new_data(sort_method, new_configs_train, new_energies_train, new_foms_train)\n",
    "        new_configs_test, new_energies_test, new_foms_test    = sort_new_data(sort_method, new_configs_test, new_energies_test, new_foms_test)\n",
    "    if len(new_foms_train):\n",
    "        print(f\"這個iter最小的foms_train: {np.min(new_foms_train)}\")\n",
    "    # # 刪除前xx%的原始數據（之後寫成函數）\n",
    "    # xx = 0.1\n",
    "    # n_remove_train = int(len(foms_train) * xx)\n",
    "    # n_remove_test  = int(len(foms_test) * xx)\n",
    "    # configs_train, configs_test = configs_train[n_remove_train:], configs_test[n_remove_test:]\n",
    "    # foms_train, foms_test = foms_train[n_remove_train:], foms_test[n_remove_test:]\n",
    "    # 新增到dataset\n",
    "    configs_train, configs_test = np.r_[configs_train, new_configs_train], np.r_[configs_test, new_configs_test]\n",
    "    foms_train, foms_test       = np.r_[foms_train, new_foms_train], np.r_[foms_test, new_foms_test]\n",
    "    training_set, testing_set   = [configs_train, foms_train], [configs_test, foms_test]\n",
    "\n",
    "    ################################對照exact##################################\n",
    "    if rings <= 16:    # rings太大不要用到Exact Solver\n",
    "        sampler_temp = dimod.ExactSolver()\n",
    "        sampleset_temp = sampler_temp.sample(model.bqm())\n",
    "        energy_temp = sampleset_temp.record[\"energy\"]\n",
    "        ascending_indices = np.argsort(energy_temp)\n",
    "        energy_temp_sorted = energy_temp[ascending_indices]\n",
    "    \n",
    "        arr = find_indices(energy_temp_sorted, new_energies_train) + 1\n",
    "        arr_str = \", \".join(map(str, arr))\n",
    "        print(f\"new energies實際上是第幾小的: [{arr_str}]\")\n",
    "        print(f\"這些energies的值: [{', '.join(map(str, new_energies_train))}]\")\n",
    "        print(f\"這些energies對應的FOM: [{', '.join(map(str, new_foms_train))}]\")\n",
    "    ###########################################################################\n",
    "    \n",
    "    # 紀錄所有新增的energies跟foms（只記錄training set的）\n",
    "    energy_ls.extend( new_energies_train )\n",
    "    fom_ls.extend( new_foms_train )\n",
    "    if len(num_in_iter) == 0:\n",
    "        num_in_iter.append( new_data_split_idx )\n",
    "    else:\n",
    "        num_in_iter.append( num_in_iter[-1] + new_data_split_idx )\n",
    "    \n",
    "    # 分割線\n",
    "    print(\"*\" * 50)\n",
    "    \n",
    "    # 自增1\n",
    "    i += 1\n",
    "\n",
    "    # 跑完指定的iteration\n",
    "    # if i >= iteration:\n",
    "        \n",
    "    #     # 計時結束\n",
    "    #     end_time = time.time()\n",
    "    #     elapsed_time = end_time - start_time\n",
    "    #     print(f\"跑完所有iteration的時間: {elapsed_time: .2f} 秒\")\n",
    "\n",
    "    #     # 顯示整個iteration的loss\n",
    "    #     if testing_losses:\n",
    "    #         plot_loss_iter(training_losses, testing_losses)\n",
    "        \n",
    "    #     # 顯示energy - ith config, fom - ith config\n",
    "    #     plot_energy_fom(energy_ls, fom_ls, num_in_iter, show=True, save=False)\n",
    "        \n",
    "    #     # 顯示FOMs對i-th configuration的圖 & 最小FOM的configuration資訊\n",
    "    #     print(f\"最小的fom是: {np.min(foms_train)}\")\n",
    "    #     print(f\"他的index是: {np.argmin(foms_train)}\")\n",
    "    #     print(f\"這個fom對應的config是: [{', '.join(map(str, configs_train[np.argmin(foms_train)]))}]\")\n",
    "    #     plot_foms(foms_train, split_idx=split_idx, original=True, modified=True, show=True)\n",
    "        \n",
    "    #     # 詢問還要跑幾次，如果不要跑了就輸入0\n",
    "    #     iteration = int( input(\"還要跑幾次iteration: \") )\n",
    "    #     i = 0\n",
    "    #     start_time = time.time()\n",
    "\n",
    "\n",
    "# 顯示FOMs對i-th configuration的圖 & 最小FOM的configuration資訊\n",
    "print(f\"最小的fom是: {np.min(foms_train)}\")\n",
    "print(f\"他的index是: {np.argmin(foms_train)}\")\n",
    "print(f\"這個fom對應的config是: [{', '.join(map(str, configs_train[np.argmin(foms_train)]))}]\")\n",
    "plot_foms(foms_train, split_idx=split_idx, original=True, modified=True, show=True)\n",
    "with open('1000+200x15.txt', 'a') as f:\n",
    "    f.write(str(np.min(foms_train)) + '\\n')\n",
    "    f.close()\n",
    "\n",
    "print(\"跑完全部的iteration啦!! \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769e4206-9bc0-4eb2-9e24-1a713cc174c9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_foms(foms_train, split_idx=split_idx, original=True, modified=True, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57066b4f-b8b6-430f-8762-4c5afa26f56f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Unit Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7937eefb-2c95-4fab-847b-1ca666d9b45f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Test the function \"foms_calc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ad814f-7a4c-4ac2-96ce-36dfb0777b49",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# foms = foms_calc(configs_train, resolution, multiple, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3433e5b-0a8a-480e-a8ca-cd5dc1810b91",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# idx = 40\n",
    "# print(f\"[{', '.join(map(str, configs_train[idx]))}]\")\n",
    "# print(foms[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdacc063-038a-46d7-b4ec-17b97d192242",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Test the functions \"add_new_data\" & \"sort_new_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ce8792-0e0c-4aa1-b775-ec508736f6a3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Initialize the model\n",
    "# model = FactorizationMachine(input_size=rings, factorization_size=K, act=\"identity\")\n",
    "# model.init_params(initializer=mx.init.Normal())\n",
    "\n",
    "# # Training the model\n",
    "# model.train(configs_train, foms_train, num_epoch=num_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f43712-7c1f-48a2-96b9-db80b7cc6542",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# num_reads = 10\n",
    "# num_adds  = 3\n",
    "# add_method  = \"min_fom\"\n",
    "# sort_method = \"fom_ascent\"\n",
    "\n",
    "# # SA\n",
    "# sampler = dimod.SimulatedAnnealingSampler()\n",
    "# sampleset = sampler.sample(model.bqm(), num_reads=num_reads)\n",
    "# foms = foms_calc(sampleset.record[\"sample\"], resolution, multiple, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd46379-ef6f-4f58-a3f8-dea7ae63de95",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def print_configs(configs):\n",
    "#     for i, config in enumerate(configs):\n",
    "#         print(f\"{i+1}. [{', '.join(map(str, config))}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ab76c5-caef-4da7-b004-6d809ee1909f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # original\n",
    "# print_configs(sampleset.record[\"sample\"])\n",
    "# print(sampleset.record[\"energy\"])\n",
    "# print(foms)\n",
    "# print(\"*\" * 50)\n",
    "\n",
    "# # add_new_data\n",
    "# new_configs, new_energies, new_foms = add_new_data(add_method, sampleset, num_adds, resolution=resolution, multiple=multiple, target=target)\n",
    "# print_configs(new_configs)\n",
    "# print(new_energies)\n",
    "# print(new_foms)\n",
    "# print(\"*\" * 50)\n",
    "\n",
    "# # sort_new_data\n",
    "# new_configs, new_energies, new_foms = sort_new_data(sort_method, new_configs, new_energies, new_foms)\n",
    "# print_configs(new_configs)\n",
    "# print(new_energies)\n",
    "# print(new_foms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0f74b8-1526-41af-bde9-20c49769c15a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Test the \"original FM\" & the function \"dynamic_FM\"\n",
    "<pre>\n",
    "- Examine the time for training when the dataset is large\n",
    "- Examine the time for saving model when the dataset is large\n",
    "- Test if the method \"load_model\" works well\n",
    "- Test if the function \"dynamic_FM\" works well\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b9bd59-f73e-4dd8-b2c9-2c972fd31e53",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Define some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99940b0-f4bb-44a3-ac56-bd2a0c32baa3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 查看模型參數的說明 -> \"for name, param in model.collect_params().items()\"這個loop會隨著training set越大而跑的越慢\n",
    "################################################################################################################\n",
    "# def inspect_model_params(model):\n",
    "#     total_size = 0\n",
    "#     print(\"Model parameters:\")\n",
    "    \n",
    "#     for name, param in model.collect_params().items():\n",
    "#         if param.grad_req != 'null':  # 確保是可訓練參數\n",
    "#             param_data = param.data()\n",
    "#             param_size = param_data.size * np.dtype(param_data.dtype).itemsize  # 計算記憶體大小 (bytes)\n",
    "#             total_size += param_size\n",
    "#             print(f\" - {name}: shape={param.shape}, size={param_data.size}, memory={param_size / 1024:.2f} KB\")\n",
    "\n",
    "#     print(f\"Total parameter memory: {total_size / (1024 * 1024):.2f} MB\")\n",
    "################################################################################################################\n",
    "# def inspect_model_params(model):\n",
    "#     mx.nd.waitall()  # 確保所有運算完成，避免阻塞\n",
    "#     total_size = 0\n",
    "#     print(\"Model parameters:\")\n",
    "\n",
    "#     for name, param in model.collect_params().items():\n",
    "#         param_data = param.data(ctx=mx.cpu())  # 確保不會觸發 GPU → CPU 傳輸\n",
    "#         param_size = param_data.size * np.dtype(param_data.dtype).itemsize\n",
    "#         total_size += param_size\n",
    "#         print(f\" - {name}: shape={param.shape}, size={param_data.size}, memory={param_size / 1024:.2f} KB\")\n",
    "\n",
    "#     print(f\"Total parameter memory: {total_size / (1024 * 1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0f6e98-5b23-494c-bfec-983d1ae21a25",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 查看模型參數的內容\n",
    "# def show_model_parameters(model):\n",
    "#     mx.nd.waitall()  # 確保所有運算完成，避免阻塞\n",
    "#     print(\"Model parameters:\")\n",
    "#     for name, param in model.collect_params().items():\n",
    "#         param_data = param.data(ctx=mx.cpu()).asnumpy()  # 轉換為 NumPy 陣列以便顯示\n",
    "#         print(f\" - {name}:\")\n",
    "#         print(param_data)  # 直接輸出完整參數值\n",
    "#         print()  # 增加換行方便閱讀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a1fc17-4361-43dd-9a49-1c73a1972c9b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 使用pickle存模型 -> 結果：large dataset訓練出來的model還是存很久\n",
    "\n",
    "# def save_params_pickle(model, path=\"model.pkl\"):\n",
    "#     param_dict = {name: param for name, param in model.collect_params().items()}\n",
    "#     with open(path, \"wb\") as f:\n",
    "#         pickle.dump(param_dict, f)\n",
    "#     print(f\"Saved model parameters to {path}\")\n",
    "\n",
    "# def load_params_pickle(model, path=\"model.pkl\"):\n",
    "#     with open(path, \"rb\") as f:\n",
    "#         param_dict = pickle.load(f)\n",
    "#     for name, param in model.collect_params().items():\n",
    "#         if name in param_dict:\n",
    "#             param.set_data(param_dict[name].data())\n",
    "#     print(f\"Loaded model parameters from {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11120e1-5ec3-4d5d-a04d-1f16b3cb48b3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 使用numpy存模型 -> 結果：large dataset訓練出來的model還是存很久\n",
    "\n",
    "# def save_params_manual(model, path=\"manual_model.npz\"):\n",
    "#     \"\"\"手動儲存模型參數\"\"\"\n",
    "#     param_dict = {name: param.data().asnumpy() for name, param in model.collect_params().items()}\n",
    "#     np.savez(path, **param_dict)\n",
    "#     print(f\"Saved model parameters to {path}\")\n",
    "\n",
    "# def load_params_manual(model, path=\"manual_model.npz\"):\n",
    "#     \"\"\"手動載入模型參數\"\"\"\n",
    "#     loaded_data = np.load(path)\n",
    "#     for name, param in model.collect_params().items():\n",
    "#         if name in loaded_data:\n",
    "#             param.set_data(mx.nd.array(loaded_data[name]))\n",
    "#     print(f\"Loaded model parameters from {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d991d38-d733-4795-945c-c632c915bd90",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Examine the training & saving parameters time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c63a366-0a3e-4479-8dc7-4ae325bb8839",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# var_num = 64\n",
    "# K = var_num\n",
    "# dataset_size = 200_000\n",
    "# xs = np.random.randint(2, size=(dataset_size, var_num), dtype=np.int8)\n",
    "# ys = np.empty(dataset_size, dtype=np.float64)\n",
    "# split_idx = int( dataset_size / 2)\n",
    "# training_set = [xs[:split_idx], ys[:split_idx]]\n",
    "# testing_set  = [xs[split_idx:], ys[split_idx:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381d35b0-676d-401b-a9a3-b23c01237452",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = FactorizationMachine(input_size=var_num, factorization_size=K, act=\"identity\")\n",
    "# model.init_params(initializer=mx.init.Normal())\n",
    "\n",
    "# start_time = time.time()\n",
    "# model.train(xs, ys, num_epoch=100)\n",
    "# # model = dynamic_FM(var_num, K, training_set, testing_set, show=False)\n",
    "# end_time = time.time()\n",
    "# print(f\"training time: {end_time - start_time}\")\n",
    "\n",
    "# start_time = time.time()\n",
    "# model.save_parameters(\"temp.params\")\n",
    "# end_time = time.time()\n",
    "# print(f\"saving time: {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f51c0d5-0104-40a3-aa2b-f3823dd54976",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Test if the method \"load_model\" works well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c1bc40-88e6-4500-92fc-85f774bd25bc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# var_num = 3\n",
    "# K = var_num\n",
    "\n",
    "# dataset_size = 20_000\n",
    "# xs = np.random.randint(2, size=(dataset_size, var_num), dtype=np.int8)\n",
    "# ys = np.empty(dataset_size, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5927a422-0a3d-498c-9940-e60729e2fa9d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = FactorizationMachine(input_size=var_num, factorization_size=K, act=\"identity\")\n",
    "# model.init_params(initializer=mx.init.Normal())\n",
    "# show_model_parameters(model)\n",
    "\n",
    "# model.train(xs, ys)\n",
    "\n",
    "# show_model_parameters(model)\n",
    "# model.save_model(\"temp.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10235bc2-b61e-4479-ae3d-d9c6d92a3703",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = FactorizationMachine.load_model(var_num, K, \"temp.params\")\n",
    "# show_model_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bee02e-2b8a-4e8b-b538-7ca8e66b8973",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Test if the function \"dynamic_FM\" works well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca41eb5-f1c1-4ec2-b113-42fcf44cf7f8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dynamic_retrain = True\n",
    "# model = dynamic_FM(dynamic_retrain, rings, K, training_set, testing_set, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c328f07-e2f2-441d-8b97-9e83328ffb14",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # rm_best_model()\n",
    "# dynamic_retrain = False\n",
    "# model = dynamic_FM(dynamic_retrain, rings, K, training_set, testing_set, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f84b6e-d7be-455c-860e-d6077a2567ae",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "s4_multilayer_FOM([1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af9a0e9-8c14-420c-86f9-ff8f7f00514b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_layer = 30\n",
    "print_spectrum = 1\n",
    "print_TR_percent = 1\n",
    "sio2_thick = 0.01\n",
    "ag_thick = 0.005\n",
    "hfo2_thick = 0.01\n",
    "al2o3_thick = 0.01\n",
    "al_thick = 0.005\n",
    "def n_al2o3(wl):\n",
    "    nsq = 1 + 1.4313493*wl**2/(wl**2-0.0726631**2) + 0.65054713*wl**2/(wl**2-0.1193242**2) + 5.3414021*wl**2/(wl**2-18.028251**2)\n",
    "    return (nsq)\n",
    "def n_sio2(wl):\n",
    "    nsq = 1 + 0.6961663*wl**2/(wl**2-0.0684043**2) + 0.4079426*wl**2/(wl**2-0.1162414**2) + 0.8974794*wl**2/(wl**2-9.896161**2)\n",
    "    return (nsq)\n",
    "def n_hfo2(wl):\n",
    "    return (np.square(1.875 + 6.28e-3/(wl**2) + 5.8e-4/(wl**4)))\n",
    "\n",
    "def s4_multilayer_FOM(x):\n",
    "    #新しいシミュレーションオブジェクトを設定\n",
    "    S=S4.New(Lattice=((1,0),(0,1)),NumBasis=1)\n",
    "    #S.SetOptions(PolarizationDecomposition = True)\n",
    "    pmma_string = 'PMMA'\n",
    "    sio2_string = 'SiO2'\n",
    "    sic_string  = 'SiC' \n",
    "    #materialの設定\n",
    "    S.SetMaterial(Name='Vacuum',Epsilon=1)\n",
    "    S.SetMaterial(Name='Si',Epsilon=3.4**2)\n",
    "    S.SetMaterial(Name='SiO2',Epsilon=1.5**2)\n",
    "    S.SetMaterial(Name='SiC',Epsilon=3.0**2)\n",
    "    S.SetMaterial(Name='PMMA',Epsilon=1.48**2)\n",
    "    S.SetMaterial(Name='Ag',Epsilon=5**2)\n",
    "    S.SetMaterial(Name='HfO2',Epsilon=5**2)\n",
    "    S.SetMaterial(Name='Al2O3',Epsilon=5**2)\n",
    "    S.SetMaterial(Name='Al',Epsilon=5**2)\n",
    "    #レイヤーを設定今回は3つのレイヤー。\n",
    "   \n",
    "        \n",
    "        \n",
    "    S.AddLayer(Name='Level0',Thickness=0.0, Material='Vacuum')\n",
    "    \n",
    "    if(x[(total_layer-4)*2]==0 and x[(total_layer-4)*2+1]==0):\n",
    "        sio2_thick = 0.005\n",
    "    elif(x[(total_layer-4)*2]==0 and x[(total_layer-4)*2+1]==1):\n",
    "        sio2_thick = 0.01\n",
    "    elif(x[(total_layer-4)*2]==1 and x[(total_layer-4)*2+1]==0):\n",
    "        sio2_thick = 0.015\n",
    "    elif(x[(total_layer-4)*2]==1 and x[(total_layer-4)*2+1]==1):\n",
    "        sio2_thick = 0.02\n",
    "\n",
    "    if(x[(total_layer-3)*2]==0 and x[(total_layer-3)*2+1]==0):\n",
    "        ag_thick = 0.005\n",
    "    elif(x[(total_layer-3)*2]==0 and x[(total_layer-3)*2+1]==1):\n",
    "        ag_thick = 0.006\n",
    "    elif(x[(total_layer-3)*2]==1 and x[(total_layer-3)*2+1]==0):\n",
    "        ag_thick = 0.007\n",
    "    elif(x[(total_layer-3)*2]==1 and x[(total_layer-3)*2+1]==1):\n",
    "        ag_thick = 0.008\n",
    "\n",
    "    if(x[(total_layer-2)*2]==0 and x[(total_layer-2)*2+1]==0):\n",
    "        hfo2_thick = 0.005\n",
    "    elif(x[(total_layer-2)*2]==0 and x[(total_layer-2)*2+1]==1):\n",
    "        hfo2_thick = 0.01\n",
    "    elif(x[(total_layer-2)*2]==1 and x[(total_layer-2)*2+1]==0):\n",
    "        hfo2_thick = 0.015\n",
    "    elif(x[(total_layer-2)*2]==1 and x[(total_layer-2)*2+1]==1):\n",
    "        hfo2_thick = 0.02\n",
    "\n",
    "    if(x[(total_layer-1)*2]==0 and x[(total_layer-1)*2+1]==0):\n",
    "        al2o3_thick = 0.005\n",
    "    elif(x[(total_layer-1)*2]==0 and x[(total_layer-1)*2+1]==1):\n",
    "        al2o3_thick = 0.01\n",
    "    elif(x[(total_layer-1)*2]==1 and x[(total_layer-1)*2+1]==0):\n",
    "        al2o3_thick= 0.015\n",
    "    elif(x[(total_layer-1)*2]==1 and x[(total_layer-1)*2+1]==1):\n",
    "        al2o3_thick = 0.02\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    for layercount in range(total_layer-4):\n",
    "        if(x[layercount]==0 and x[layercount+total_layer-4]==0):\n",
    "            S.AddLayer(Name=str(layercount), Thickness=sio2_thick, Material='SiO2')\n",
    "        elif(x[layercount]==0 and x[layercount+total_layer-4]==1):\n",
    "            S.AddLayer(Name=str(layercount), Thickness=ag_thick, Material='Ag')\n",
    "        elif(x[layercount]==1 and x[layercount+total_layer-4]==0):\n",
    "            S.AddLayer(Name=str(layercount), Thickness=hfo2_thick, Material='HfO2')\n",
    "        elif(x[layercount]==1 and x[layercount+total_layer-4]==1):\n",
    "            S.AddLayer(Name=str(layercount), Thickness=al2o3_thick, Material='Al2O3')\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    S.AddLayer(Name='Air',Thickness=0.0,Material='Vacuum')\n",
    "    #S.AddLayerCopy(Name = 'Air', Thickness = 0.0, Layer = 'Level0')\n",
    "    \n",
    "    #波長範囲を設定\n",
    "    wavelength_array=np.linspace(0.4,2,80)\n",
    "    #print(wavelength_array)\n",
    "    wavelength_array_inside = [0.4      , 0.42025316, 0.44050633, 0.46075949, 0.48101266,\n",
    "                               0.50126582, 0.52151899, 0.54177215, 0.56202532, 0.58227848,\n",
    "                               0.60253165, 0.62278481, 0.64303797, 0.66329114, 0.6835443,  0.70379747 ]\n",
    "    wavelength_array_outside1 = [0.72405063 ,0.7443038\n",
    "                                ,0.76455696 ,0.78481013, 0.80506329, 0.82531646, 0.84556962, 0.86582278\n",
    "                                ,0.88607595 ,0.90632911, 0.92658228, 0.94683544, 0.96708861, 0.98734177\n",
    "                                ,1.00759494 ,1.0278481 , 1.04810127, 1.06835443, 1.08860759, 1.10886076\n",
    "                                ,1.12911392 ,1.14936709, 1.16962025, 1.18987342, 1.21012658, 1.23037975\n",
    "                                ,1.25063291 ,1.27088608, 1.29113924, 1.31139241, 1.33164557, 1.35189873\n",
    "                                ,1.3721519  ,1.39240506, 1.41265823, 1.43291139, 1.45316456, 1.47341772\n",
    "                                ,1.49367089 ,1.51392405, 1.53417722, 1.55443038, 1.57468354, 1.59493671\n",
    "                                ,1.61518987 ,1.63544304, 1.6556962 , 1.67594937, 1.69620253, 1.7164557\n",
    "                                ,1.73670886 ,1.75696203, 1.77721519, 1.79746835, 1.81772152, 1.83797468\n",
    "                                ,1.85822785 ,1.87848101, 1.89873418, 1.91898734, 1.93924051, 1.95949367\n",
    "                                ,1.97974684 ,2.0        ]\n",
    "    Planck_array = np.array( [72203 , 100131, 133343, 171499, 214049,\n",
    "                                       260285, 309395, 360519, 412793, 465387,\n",
    "                                       517531, 568535, 617802, 664829, 709210,\n",
    "                                       750632, 788866, 823761, 855234, 883262,\n",
    "                                       907872, 929131, 947141, 962029, 973942,\n",
    "                                       983041, 989499, 993489, 995191, 994782,\n",
    "                                       992435, 988321, 982603, 975436, 966971,\n",
    "                                       957346, 946694, 935139, 922796,\n",
    "                                       909770, 889167, 874851, 860165, 845182,\n",
    "                                       829968, 814583, 799083, 783516, 767926, \n",
    "                                       752353, 736833, 721398, 706074, 690887, \n",
    "                                       675859, 661007, 646350, 631899, 617669,\n",
    "                                       603668, 589905, 576386, 563118, 550104,\n",
    "                                       537348, 524850, 512613, 500637, 488921,\n",
    "                                       477464, 466265, 455321, 444631, 434190,\n",
    "                                       423997, 414047, 404336, 394862, 385619,\n",
    "                                       372180])\n",
    "    Planck_normalized_array = Planck_array#/9.95282\n",
    "    \n",
    "    #効率計算結果用アレイ\n",
    "    efficiency_array=[]\n",
    "    reflected_flux_array = []\n",
    "    emissive_array = []\n",
    "    reflected_flux_array_outside1 = []\n",
    "    reflected_flux_array_outside2 = []\n",
    "    reflected_flux_array_inside = []\n",
    "    efficiency_array_outside = []\n",
    "    reflected_flux_outside  = []\n",
    "    efficiency_array_inside = []\n",
    "    reflected_flux_inside = [] \n",
    "\n",
    "    HfO2_array = [\n",
    "        \n",
    "    ]\n",
    "    Al2O3_array = [\n",
    "        \n",
    "    ]\n",
    "    \n",
    "    SiC_array = [11.959+ 4.7869j\n",
    "    ,11.893+ 4.3625j\n",
    "    ,11.851+ 4.0079j\n",
    "    ,11.816+ 3.6938j\n",
    "    ,11.794+ 3.3971j\n",
    "    ,11.756+ 3.1279j\n",
    "    ,11.714+ 2.8820j\n",
    "    ,11.665+ 2.6576j\n",
    "    ,11.614+ 2.4576j\n",
    "    ,11.561+ 2.2745j\n",
    "    ,11.510+ 2.1070j\n",
    "    ,11.456+ 1.9535j\n",
    "    ,11.393+ 1.8099j\n",
    "    ,11.337+ 1.6870j\n",
    "    ,11.281+ 1.5770j\n",
    "    ,11.227+ 1.4723j\n",
    "    ,11.179+ 1.3799j\n",
    "    ,11.128+ 1.2891j\n",
    "    ,11.082+ 1.2112j\n",
    "    ,11.036+ 1.1316j\n",
    "    ,10.982+ 1.0604j\n",
    "    ,10.932+ 1.0079j\n",
    "    ,10.898+ 0.9507j\n",
    "    ,10.846+ 0.9045j\n",
    "    ,10.815+ 0.8471j\n",
    "    ,10.776+ 0.8223j\n",
    "    ,10.759+ 0.7672j\n",
    "    ,10.726+ 0.7301j\n",
    "    ,10.689+ 0.6723j\n",
    "    ,10.655+ 0.6473j\n",
    "    ,10.620+ 0.6224j\n",
    "    ,10.586+ 0.5976j\n",
    "    ,10.552+ 0.5728j\n",
    "    ,10.525+ 0.5513j\n",
    "    ,10.504+ 0.5325j\n",
    "    ,10.483+ 0.5137j\n",
    "    ,10.462+ 0.4949j\n",
    "    ,10.441+ 0.4762j\n",
    "    ,10.420+ 0.4575j\n",
    "    ,10.403+ 0.4402j\n",
    "    ,10.378+ 0.4150j\n",
    "    ,10.362+ 0.3983j\n",
    "    ,10.346+ 0.3816j\n",
    "    ,10.330+ 0.3649j\n",
    "    ,10.313+ 0.3483j\n",
    "    ,10.297+ 0.3317j\n",
    "    ,10.283+ 0.3206j\n",
    "    ,10.269+ 0.3098j\n",
    "    ,10.256+ 0.2990j\n",
    "    ,10.242+ 0.2882j\n",
    "    ,10.228+ 0.2774j\n",
    "    ,10.214+ 0.2667j\n",
    "    ,10.201+ 0.2559j\n",
    "    ,10.187+ 0.2452j\n",
    "    ,10.173+ 0.2345j\n",
    "    ,10.161+ 0.2262j\n",
    "    ,10.151+ 0.2197j\n",
    "    ,10.141+ 0.2132j\n",
    "    ,10.131+ 0.2068j\n",
    "    ,10.121+ 0.2003j\n",
    "    ,10.111+ 0.1939j\n",
    "    ,10.101+ 0.1874j\n",
    "    ,10.091+ 0.1810j\n",
    "    ,10.081+ 0.1746j\n",
    "    ,10.071+ 0.1682j\n",
    "    ,10.061+ 0.1618j\n",
    "    ,10.051+ 0.1554j\n",
    "    ,10.041+ 0.1491j\n",
    "    ,10.032+ 0.1438j\n",
    "    ,10.023+ 0.1385j\n",
    "    ,10.014+ 0.1333j\n",
    "    ,10.006+ 0.1280j\n",
    "    ,9.9969+ 0.1227j\n",
    "    ,9.9881+ 0.1175j\n",
    "    ,9.9794+ 0.1123j\n",
    "    ,9.9711+ 0.1084j\n",
    "    ,9.9631+ 0.1052j\n",
    "    ,9.9552+ 0.1020j\n",
    "    ,9.9472+ 0.0988j\n",
    "    ,9.9352+ 0.0941j ]\n",
    "\n",
    "\n",
    "    \n",
    "    Ag_array= [-4.5730+0.23090j\n",
    "    ,-5.6067+0.23916j\n",
    "    ,-6.6569+0.26761j\n",
    "    ,-7.7231+0.28956j\n",
    "    ,-8.8055+0.31331j\n",
    "    ,-9.9352+0.32785j\n",
    "    ,-11.090+0.34592j\n",
    "    ,-12.289+0.36117j\n",
    "    ,-13.543+0.36946j\n",
    "    ,-14.821+0.38399j\n",
    "    ,-16.151+0.39432j\n",
    "    ,-17.535+0.40347j\n",
    "    ,-18.957+0.42822j\n",
    "    ,-20.420+0.45177j\n",
    "    ,-21.924+0.47418j\n",
    "    ,-23.468+0.49476j\n",
    "    ,-25.059+0.51481j\n",
    "    ,-26.693+0.53629j\n",
    "    ,-28.375+0.55852j\n",
    "    ,-30.100+0.58312j\n",
    "    ,-31.866+0.61038j\n",
    "    ,-33.683+0.63822j\n",
    "    ,-35.549+0.67139j\n",
    "    ,-37.465+0.70572j\n",
    "    ,-39.431+0.74107j\n",
    "    ,-41.420+0.78426j\n",
    "    ,-43.458+0.82865j\n",
    "    ,-45.545+0.87425j\n",
    "    ,-47.674+0.92080j\n",
    "    ,-49.850+0.96840j\n",
    "    ,-52.074+ 1.0172j\n",
    "    ,-53.460+ 1.0477j\n",
    "    ,-55.726+ 1.1005j\n",
    "    ,-58.023+ 1.1600j\n",
    "    ,-60.367+ 1.2209j\n",
    "    ,-62.757+ 1.2833j\n",
    "    ,-65.194+ 1.3472j\n",
    "    ,-67.662+ 1.4124j\n",
    "    ,-70.16 + 1.4790j\n",
    "    ,-72.720+ 1.5471j\n",
    "    ,-76.633+ 1.6519j\n",
    "    ,-79.299+ 1.7237j\n",
    "    ,-82.011+ 1.7961j\n",
    "    ,-84.770+ 1.8692j\n",
    "    ,-87.574+ 1.9437j\n",
    "    ,-90.417+ 2.0197j\n",
    "    ,-93.284+ 2.0975j\n",
    "    ,-96.196+ 2.1768j\n",
    "    ,-99.152+ 2.2574j\n",
    "    ,-102.17+ 2.3447j\n",
    "    ,-105.25+ 2.4370j\n",
    "    ,-108.37+ 2.5310j\n",
    "    ,-111.54+ 2.6267j\n",
    "    ,-114.74+ 2.7251j\n",
    "    ,-117.96+ 2.8261j\n",
    "    ,-121.23+ 2.9289j\n",
    "    ,-124.54+ 3.0334j\n",
    "    ,-127.90+ 3.1397j\n",
    "    ,-131.30+ 3.2501j\n",
    "    ,-134.75+ 3.3624j\n",
    "    ,-138.24+ 3.4765j\n",
    "    ,-141.78+ 3.5924j\n",
    "    ,-145.36+ 3.7101j\n",
    "    ,-149.02+ 3.8350j\n",
    "    ,-152.72+ 3.9628j\n",
    "    ,-156.47+ 4.0926j\n",
    "    ,-160.27+ 4.2244j\n",
    "    ,-164.11+ 4.3581j\n",
    "    ,-168.00+ 4.4938j\n",
    "    ,-171.87+ 4.6422j\n",
    "    ,-175.79+ 4.7935j\n",
    "    ,-179.74+ 4.9470j\n",
    "    ,-183.75+ 5.1026j\n",
    "    ,-187.80+ 5.2605j\n",
    "    ,-191.89+ 5.4206j\n",
    "    ,-196.02+ 5.5846j\n",
    "    ,-200.20+ 5.7602j\n",
    "    ,-204.42+ 5.9382j\n",
    "    ,-208.69+ 6.1187j\n",
    "    ,-215.17+ 6.3940j]\n",
    "    \n",
    "    SiO2_array =[2.2025+0.0j\n",
    "    ,2.1968+0.0j\n",
    "    ,2.1920+0.0j\n",
    "    ,2.1878+0.0j\n",
    "    ,2.1841+0.0j\n",
    "    ,2.1809+0.0j\n",
    "    ,2.1781+0.0j           \n",
    "    ,2.1755+0.0j          \n",
    "    ,2.1733+0.0j          \n",
    "    ,2.1713+0.0j\n",
    "    ,2.1695+0.0j\n",
    "    ,2.1679+0.0j\n",
    "    ,2.1664+0.0j\n",
    "    ,2.1650+0.0j\n",
    "    ,2.1638+0.0j\n",
    "    ,2.1627+0.0j\n",
    "    ,2.1617+0.0j\n",
    "    ,2.1608+0.0j\n",
    "    ,2.1599+0.0j\n",
    "    ,2.1591+0.0j\n",
    "    ,2.1584+0.0j\n",
    "    ,2.1577+0.0j\n",
    "    ,2.1571+0.0j\n",
    "    ,2.1565+0.0j\n",
    "    ,2.1559+0.0j\n",
    "    ,2.1553+0.0j\n",
    "    ,2.1547+0.0j\n",
    "    ,2.1541+0.0j\n",
    "    ,2.1535+0.0j\n",
    "    ,2.1529+0.0j\n",
    "    ,2.1523+0.0j\n",
    "    ,2.1517+0.0j\n",
    "    ,2.1511+0.0j\n",
    "    ,2.1505+0.0j\n",
    "    ,2.1499+0.0j\n",
    "    ,2.1493+0.0j\n",
    "    ,2.1487+0.0j\n",
    "    ,2.1481+0.0j\n",
    "    ,2.1475+0.0j\n",
    "    ,2.1471+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j\n",
    "    ,2.1467+0.0j ] \n",
    "    \n",
    "    Al_array= [-23.144+4.7182j\n",
    "    ,-25.589+5.5127j\n",
    "    ,-28.145+6.4195j\n",
    "    ,-30.731+7.4949j\n",
    "    ,-33.395+8.6579j\n",
    "    ,-36.090+9.9091j\n",
    "    ,-38.872+11.265j\n",
    "    ,-41.710+12.807j\n",
    "    ,-44.643+14.429j\n",
    "    ,-47.493+16.359j\n",
    "    ,-50.406+18.401j\n",
    "    ,-53.354+20.582j\n",
    "    ,-56.098+23.131j\n",
    "    ,-58.640+25.854j\n",
    "    ,-60.999+28.736j\n",
    "    ,-62.933+31.901j\n",
    "    ,-64.704+35.228j\n",
    "    ,-65.238+38.813j\n",
    "    ,-65.274+42.509j\n",
    "    ,-63.977+45.423j\n",
    "    ,-61.615+46.062j\n",
    "    ,-60.201+45.005j\n",
    "    ,-59.941+42.950j\n",
    "    ,-60.318+39.930j\n",
    "    ,-60.709+36.927j\n",
    "    ,-64.186+33.671j\n",
    "    ,-68.333+30.708j\n",
    "    ,-73.343+28.403j\n",
    "    ,-79.497+27.064j\n",
    "    ,-84.779+27.151j\n",
    "    ,-89.852+27.369j\n",
    "    ,-94.605+27.627j\n",
    "    ,-99.324+27.942j\n",
    "    ,-104.10+28.269j\n",
    "    ,-108.98+28.581j\n",
    "    ,-113.97+28.880j\n",
    "    ,-119.06+29.192j\n",
    "    ,-124.15+29.750j\n",
    "    ,-129.35+30.306j\n",
    "    ,-134.66+30.861j\n",
    "    ,-140.07+31.413j\n",
    "    ,-145.58+31.964j\n",
    "    ,-151.15+32.680j\n",
    "    ,-156.77+33.553j\n",
    "    ,-162.49+34.436j\n",
    "    ,-168.31+35.329j\n",
    "    ,-174.24+36.232j\n",
    "    ,-180.27+37.144j\n",
    "    ,-186.40+38.067j\n",
    "    ,-192.48+39.216j\n",
    "    ,-198.61+40.462j\n",
    "    ,-204.83+41.728j\n",
    "    ,-211.15+43.014j\n",
    "    ,-217.57+44.319j\n",
    "    ,-224.08+45.644j\n",
    "    ,-230.68+46.988j\n",
    "    ,-237.38+48.351j\n",
    "    ,-244.13+49.796j\n",
    "    ,-250.78+51.470j\n",
    "    ,-257.53+53.171j\n",
    "    ,-264.36+54.898j\n",
    "    ,-271.28+56.653j\n",
    "    ,-278.29+58.434j\n",
    "    ,-285.39+60.242j\n",
    "    ,-292.58+62.077j\n",
    "    ,-299.86+63.938j\n",
    "    ,-307.23+65.826j\n",
    "    ,-314.69+67.741j\n",
    "    ,-322.14+69.745j\n",
    "    ,-329.44+71.924j\n",
    "    ,-336.83+74.134j\n",
    "    ,-344.29+76.375j\n",
    "    ,-351.84+78.647j\n",
    "    ,-359.47+80.951j\n",
    "    ,-367.18+83.286j\n",
    "    ,-374.97+85.652j\n",
    "    ,-382.84+88.049j\n",
    "    ,-390.79+90.477j\n",
    "    ,-398.83+92.936j\n",
    "    ,-406.95+95.427j    ]\n",
    "    SiO2_array_index = 0\n",
    "    SiC_array_index = 0\n",
    "    Ag_array_index = 0\n",
    "    HfO2_array_index = 0\n",
    "    Al2O3_array_index = 0\n",
    "    Al_array_index = 0\n",
    "    Planck_normalized_array_index = 0\n",
    "    for wavelength in wavelength_array:\n",
    "       \n",
    "        S.SetMaterial(Name='SiO2',Epsilon=SiO2_array[SiO2_array_index])\n",
    "        SiO2_array_index = SiO2_array_index + 1\n",
    "        S.SetMaterial(Name='SiC',Epsilon=SiC_array[SiC_array_index])\n",
    "        SiC_array_index = SiC_array_index + 1\n",
    "        S.SetMaterial(Name='Ag',Epsilon=Ag_array[Ag_array_index])\n",
    "        Ag_array_index = Ag_array_index + 1\n",
    "        S.SetMaterial(Name='HfO2',Epsilon=n_hfo2(wavelength))\n",
    "        HfO2_array_index = HfO2_array_index + 1\n",
    "        S.SetMaterial(Name='Al2O3',Epsilon=n_al2o3(wavelength))\n",
    "        Al2O3_array_index = Al2O3_array_index + 1\n",
    "        S.SetMaterial(Name='Al',Epsilon=Al_array[Al_array_index])\n",
    "        Al_array_index = Al_array_index + 1\n",
    "        S.SetFrequency((1/wavelength))\n",
    "    \n",
    "        #入射角0度のs偏光平面波を入射する。\n",
    "        S.SetExcitationPlanewave(IncidenceAngles=(0,0),sAmplitude=0,pAmplitude=1)\n",
    "        \n",
    "        #入射フラックスを取得\n",
    "        (P_incident,P_reflect)=S.GetPowerFlux(Layer='Level0')\n",
    "        \n",
    "        #各次数の透過フラックスを取得\n",
    "        #P_transmittance=S.GetPowerFluxByOrder(Layer='Air')\n",
    "        (P_air_transmittance,P_air_reflect) =S.GetPowerFlux(Layer='Air')\n",
    "        #1次回折光の効率になおす。\n",
    "        #efficiency=(P_transmittance[1][0]/P_incident).real\n",
    "        #Note that efficiency => transmittance\n",
    "        efficiency=(P_air_transmittance/P_incident).real\n",
    "        #efficiency=-(P_reflect/P_incident).real\n",
    "        #アレイに追加。\n",
    "        efficiency_array.append(efficiency)\n",
    "        reflected_flux = (-(P_reflect/P_incident)).real\n",
    "        reflected_flux_array.append(reflected_flux)\n",
    "        #emissive = (1-((P_incident + P_reflect - P_air_transmittance)/P_incident)).real\n",
    "        emissive = (1 - efficiency - reflected_flux )\n",
    "        #emissive = ( efficiency)\n",
    "        emissive_array.append(emissive)\n",
    "        \n",
    "        if(0.71<=wavelength<=2):\n",
    "            reflected_flux_array_outside1.append((emissive)*Planck_normalized_array[Planck_normalized_array_index])\n",
    "            efficiency_array_outside.append(efficiency)\n",
    "            reflected_flux_outside.append(reflected_flux)\n",
    "        elif(0<wavelength<0.71):\n",
    "            reflected_flux_array_inside.append((emissive)*Planck_normalized_array[Planck_normalized_array_index])\n",
    "            efficiency_array_inside.append(efficiency)\n",
    "            reflected_flux_inside.append(reflected_flux)\n",
    "            \n",
    "        Planck_normalized_array_index = Planck_normalized_array_index +1\n",
    "        #進捗表示。\n",
    "        #sys.stdout.write(f\"\\r wavelength={wavelength} eff={emissive}\")\n",
    "        #sys.stdout.flush()\n",
    "    \n",
    "    #matplotlibで表示\n",
    "    if(print_spectrum):\n",
    "        plt.grid()\n",
    "        plt.xlabel('wavelength [μm]')\n",
    "        plt.ylabel('transmittance reflectance absorbance')\n",
    "        plt.vlines(x = 0.4, ymin = 0, ymax = 1, colors = 'purple',linestyle='dashed')\n",
    "        plt.vlines(x = 0.7, ymin = 0, ymax = 1, colors = 'red',linestyle='dashed')\n",
    "        plt.plot(wavelength_array,efficiency_array , label = 'transmittance')\n",
    "        plt.plot(wavelength_array,reflected_flux_array, label = 'reflectance')\n",
    "        plt.plot(wavelength_array,emissive_array, label = 'absorbance')\n",
    "        plt.xlim([0.4,2])\n",
    "        plt.ylim([0,1])\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    planck_1_8 = 20.5066#/9.95282\n",
    "    planck_8_13 = 47.1002#/9.95282\n",
    "    planck_13_20 = 40.2612#/9.95282\n",
    "    planck_inside =  120571\n",
    "    planck_outside = 954989 \n",
    "    planck_all_window = integrate.simps(Planck_normalized_array, wavelength_array)\n",
    "    all_window = integrate.simps(emissive_array, wavelength_array)\n",
    "    insidewindows = integrate.simps(reflected_flux_array_inside, wavelength_array_inside)\n",
    "    outsidewindows1 = integrate.simps(reflected_flux_array_outside1, wavelength_array_outside1)\n",
    "    \n",
    "    insidewindows_T = integrate.simps(efficiency_array_inside, wavelength_array_inside)\n",
    "    outsidewindows1_T = integrate.simps(efficiency_array_outside, wavelength_array_outside1)\n",
    "    insidewindows_R = integrate.simps(reflected_flux_inside, wavelength_array_inside)\n",
    "    outsidewindows1_R = integrate.simps(reflected_flux_outside, wavelength_array_outside1)\n",
    "    if(print_TR_percent):\n",
    "        print(insidewindows_T/0.303 )\n",
    "        print(outsidewindows1_R/1.297)\n",
    "    return (-(insidewindows_T/0.303 - outsidewindows1_T/1.297+ outsidewindows1_R/1.297 - insidewindows_R/0.303))\n",
    "s4_multilayer_FOM([1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c9edeb-3052-4442-b738-1199aef03631",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 179.274719,
   "end_time": "2025-04-23T09:14:21.640678",
   "environment_variables": {},
   "exception": true,
   "input_path": "superoscillation_fmqa_0411_version.ipynb",
   "output_path": "/root/fmqa/adiabatic_temp/output_run_superoscillation_fmqa_1000_200x15_10.ipynb",
   "parameters": {},
   "start_time": "2025-04-23T09:11:22.365959",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}